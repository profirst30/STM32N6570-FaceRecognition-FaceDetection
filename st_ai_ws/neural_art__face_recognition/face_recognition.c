/* AUTOGENERATED DO NOT MODIFY */

/**
  ******************************************************************************
  * @file    face_recognition.c
  * @brief   NN Code autogenerated DO NOT MODIFY IT
  ******************************************************************************
  * @attention
  *
  * Copyright (c) 2023 STMicroelectronics.
  * All rights reserved.
  *
  * This software is licensed under terms that can be found in the LICENSE file
  * in the root directory of this software component.
  * If no LICENSE file comes with this software, it is provided AS-IS.
  *
  ******************************************************************************
  */

/*
 * GIT_SHA         "e619e8606099384540d70eeaaa8091752b1bebe9"
 * GIT_BRANCH      "STAI-2.2"
 * GIT_DESCRIPTION "atonn-v1.1.1-14-ge619e8606"
 *
 * BUILD_DIR       "/c/local/jenkins_cloud/workspace/2-STEDGEAI_BuildAtonnExe_Win/git/onnx_backend/build"
 * BUILD_DATE      "25/06/2025"
 * BUILD_AUTHOR    "aitest"
 *
 * Command Line options:
 * --load-mdesc-file = "C:/ST/STEdgeAI/2.2/Utilities/configs/stm32n6"
 * --load-mpool-file = "C:/Users/DJESSOU/Desktop/opencode/STM32N6-FaceRecognition/scripts/face_recognition"
 * --cache-maintenance = true
 * --enable-virtual-mem-pools = true
 * --native-float = true
 * --json-quant-file = "C:/Users/DJESSOU/Desktop/opencode/STM32N6-FaceRecognition/converted_models/mobilefacenet_int8_faces_OE_3_3_0_Q.json"
 * --optimization = 0
 * --Os = true
 * --Omax-ca-pipe = 4
 * --Ocache-opt = true
 * --enable-epoch-controller = true
 * --output-info-file = "c_info"
 * --Oalt-sched = true
 * --onnx-input = "C:/Users/DJESSOU/Desktop/opencode/STM32N6-FaceRecognition/converted_models/mobilefacenet_int8_faces_OE_3_3_0.onnx"
 * --out-dir-prefix = "C:/Users/DJESSOU/Desktop/opencode/STM32N6-FaceRecognition/st_ai_ws/neural_art__face_recognition/"
 * --network-name = "face_recognition"
 * --all-buffers-info = true
 * --mvei = true
 */

#include "ll_aton_NN_interface.h"
#include "ll_aton.h"
#include "ll_aton_lib.h"
#include "ll_aton_version.h"
#include "ll_sw.h"
#include "ecloader.h"

#if LL_ATON_VERSION_MAJOR != 1 || LL_ATON_VERSION_MINOR != 1 || LL_ATON_VERSION_MICRO != 1 || LL_ATON_VERSION_DEV != 14
#  warning "Possible mismatch in ll_aton library used"
#endif

#if !defined(LL_ATON_DBG_BUFFER_INFO_EXCLUDED)
#  define LL_ATON_DBG_BUFFER_INFO_EXCLUDED 0
#endif

/* global pool 7 is 1.53 MB */
/* index=7 file postfix=xSPI1 name=hyperRAM offset=0x90000000  absolute_mode size=16777208 READ_WRITE THROUGHPUT=MID LATENCY=HIGH byte width=2 freq ratio=5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=ON read_power=380 write_power=340 use4initializers=YES score=82  */
/* global pool 8 is 1.07 MB */
/* index=8 file postfix=xSPI2 name=octoFlash offset=0x72000000  absolute_mode size=63963128 READ_ONLY THROUGHPUT=MID LATENCY=HIGH byte width=1 freq ratio=6 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=ON read_power=110 write_power=400 use4initializers=YES score=50  */
/* global pool 1 is 448.00 KB */
/* index=1 file postfix=AXISRAM5 name=npuRAM5 offset=0x342e0000  absolute_mode size=458752 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=18.531 write_power=16.201 use4initializers=NO score=94  */
/* global pool 2 is 448.00 KB */
/* index=2 file postfix=AXISRAM4 name=npuRAM4 offset=0x34270000  absolute_mode size=458752 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=18.531 write_power=16.201 use4initializers=NO score=94  */
/* global pool 3 is 448.00 KB */
/* index=3 file postfix=AXISRAM3 name=npuRAM3 offset=0x34200000  absolute_mode size=458752 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=18.531 write_power=16.201 use4initializers=NO score=94  */
/* global pool 0 is 84.00 KB */
/* index=0 file postfix=AXISRAM6 name=npuRAM6 offset=0x34350000  absolute_mode size=458744 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=19.006 write_power=15.79 use4initializers=NO score=94  */
/* global pool 11 is 2.39 MB */
/* index=11 file postfix=AXISRAM2_AXISRAM3_AXISRAM4_AXISRAM5_AXISRAM6 name=cpuRAM2_npuRAM3_npuRAM4_npuRAM5_npuRAM6 offset=0x34100000  absolute_mode size=2883576 vpool READ_WRITE THROUGHPUT=MID LATENCY=MID byte width=8 freq ratio=2.5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=19.006 write_power=16.201 use4initializers=NO score=85  */
/* global pool 4 is 1.00 MB */
/* index=4 file postfix=AXISRAM2 name=cpuRAM2 offset=0x34100000  absolute_mode size=1048576 READ_WRITE THROUGHPUT=MID LATENCY=MID byte width=8 freq ratio=2.5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=17.324 write_power=15.321 use4initializers=NO score=84  */
/* global pool 5 is ? */
/* index=5 file postfix=AXISRAM1 name=cpuRAM1 offset=0x34080000  absolute_mode size=0 READ_WRITE THROUGHPUT=MID LATENCY=MID byte width=8 freq ratio=2.5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=16.616 write_power=14.522 use4initializers=NO score=84  */
/* global pool 6 is ? */
/* index=6 file postfix=AXIFLEXMEM name=flexMEM offset=0x34000000  absolute_mode size=0 READ_WRITE THROUGHPUT=MID LATENCY=MID byte width=8 freq ratio=2.5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=9.381 write_power=8.569 use4initializers=NO score=84  */

LL_ATON_User_IO_Result_t LL_ATON_Set_User_Input_Buffer_face_recognition(uint32_t num, void* buffer, uint32_t size)
{
  { 
    return LL_ATON_User_IO_WRONG_INDEX;
  }
}

void *LL_ATON_Get_User_Input_Buffer_face_recognition(uint32_t num)
{
  { 
    return NULL;
  }
}

LL_ATON_User_IO_Result_t LL_ATON_Set_User_Output_Buffer_face_recognition(uint32_t num, void* buffer, uint32_t size)
{
  { 
    return LL_ATON_User_IO_WRONG_INDEX;
  }
}

void *LL_ATON_Get_User_Output_Buffer_face_recognition(uint32_t num)
{
  { 
    return NULL;
  }
}

#include "face_recognition_ecblobs.h"

/* scheduling epoch=0    nodes=336 ------------------------------------------------------------------- */

// Epoch Controller Blob (name='_ec_blob_face_recognition_1') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_1') start function
static void _ec_blob_cache_start_func_1(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 150528))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 301056))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 150528))) /* Equivalent hex address = 0x34304c00UL */, 150528);

};


/* scheduling epoch=2    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_2(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_1 */
  Quantizelinear_sw_info quantizelinear1_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 112,
    .general.input.dim.tensor_w = 112,
    .general.input.dim.tensor_c = 3,
    .general.input.dim.num_elem = 37632,
    .general.input.stride.b = 150528,
    .general.input.stride.h = 1344,
    .general.input.stride.w = 12,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 150528))) /* Equivalent hex address = 0x34304c00UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115584))) /* Equivalent hex address = 0x721105c0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116720))) /* Equivalent hex address = 0x72110a30UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 112,
    .general.output.dim.tensor_w = 112,
    .general.output.dim.tensor_c = 3,
    .general.output.dim.num_elem = 37632,
    .general.output.stride.b = 37632,
    .general.output.stride.h = 336,
    .general.output.stride.w = 3,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 301056))) /* Equivalent hex address = 0x34329800UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_1 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear1_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 301056))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 338688))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 301056))) /* Equivalent hex address = 0x34329800UL */, 37632);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_3') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_3') start function
static void _ec_blob_cache_start_func_3(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

};


/* scheduling epoch=4    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_4(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_5 */
  Dequantizelinear_sw_info dequantizelinear2_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 56,
    .general.input.dim.tensor_w = 56,
    .general.input.dim.tensor_c = 64,
    .general.input.dim.num_elem = 200704,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 64,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114592))) /* Equivalent hex address = 0x721101e0UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115728))) /* Equivalent hex address = 0x72110650UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 56,
    .general.output.dim.tensor_w = 56,
    .general.output.dim.tensor_c = 64,
    .general.output.dim.num_elem = 200704,
    .general.output.stride.b = 802816,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 256,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) /* Equivalent hex address = 0x34100000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_5 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear2_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 11 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 802816))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) /* Equivalent hex address = 0x34100000UL */, 802816);

}


/* scheduling epoch=5    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_5(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_6 */
  Activ_sw_info activ3_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 56,
    .general.input.dim.tensor_w = 56,
    .general.input.dim.tensor_c = 64,
    .general.input.dim.num_elem = 200704,
    .general.input.stride.b = 802816,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 256,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) /* Equivalent hex address = 0x34100000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 65,
    .operand.dim.num_elem = 65,
    .operand.stride.b = 260,
    .operand.stride.h = 260,
    .operand.stride.w = 260,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114032))) /* Equivalent hex address = 0x7210ffb0UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 56,
    .general.output.dim.tensor_w = 56,
    .general.output.dim.tensor_c = 64,
    .general.output.dim.num_elem = 200704,
    .general.output.stride.b = 802816,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 256,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 802816))) /* Equivalent hex address = 0x341c4000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_6 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ3_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 11 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 802816))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 1605632))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 802816))) /* Equivalent hex address = 0x341c4000UL */, 802816);

}


/* scheduling epoch=6    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_6(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_7 */
  Quantizelinear_sw_info quantizelinear4_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 56,
    .general.input.dim.tensor_w = 56,
    .general.input.dim.tensor_c = 64,
    .general.input.dim.num_elem = 200704,
    .general.input.stride.b = 802816,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 256,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 802816))) /* Equivalent hex address = 0x341c4000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114816))) /* Equivalent hex address = 0x721102c0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115952))) /* Equivalent hex address = 0x72110730UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 56,
    .general.output.dim.tensor_w = 56,
    .general.output.dim.tensor_c = 64,
    .general.output.dim.num_elem = 200704,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 64,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_7 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear4_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_7') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_7') start function
static void _ec_blob_cache_start_func_7(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

};


/* scheduling epoch=8    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_8(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_11 */
  Dequantizelinear_sw_info dequantizelinear5_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 56,
    .general.input.dim.tensor_w = 56,
    .general.input.dim.tensor_c = 64,
    .general.input.dim.num_elem = 200704,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 64,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114608))) /* Equivalent hex address = 0x721101f0UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115744))) /* Equivalent hex address = 0x72110660UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 56,
    .general.output.dim.tensor_w = 56,
    .general.output.dim.tensor_c = 64,
    .general.output.dim.num_elem = 200704,
    .general.output.stride.b = 802816,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 256,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) /* Equivalent hex address = 0x34100000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_11 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear5_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 11 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 802816))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) /* Equivalent hex address = 0x34100000UL */, 802816);

}


/* scheduling epoch=9    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_9(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_12 */
  Activ_sw_info activ6_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 56,
    .general.input.dim.tensor_w = 56,
    .general.input.dim.tensor_c = 64,
    .general.input.dim.num_elem = 200704,
    .general.input.stride.b = 802816,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 256,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) /* Equivalent hex address = 0x34100000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 65,
    .operand.dim.num_elem = 65,
    .operand.stride.b = 260,
    .operand.stride.h = 260,
    .operand.stride.w = 260,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114304))) /* Equivalent hex address = 0x721100c0UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 56,
    .general.output.dim.tensor_w = 56,
    .general.output.dim.tensor_c = 64,
    .general.output.dim.num_elem = 200704,
    .general.output.stride.b = 802816,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 256,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 1708032))) /* Equivalent hex address = 0x342a1000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_12 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ6_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 11 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 1708032))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 2510848))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 1708032))) /* Equivalent hex address = 0x342a1000UL */, 802816);

}


/* scheduling epoch=10   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_10(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_13 */
  Quantizelinear_sw_info quantizelinear7_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 56,
    .general.input.dim.tensor_w = 56,
    .general.input.dim.tensor_c = 64,
    .general.input.dim.num_elem = 200704,
    .general.input.stride.b = 802816,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 256,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 1708032))) /* Equivalent hex address = 0x342a1000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114832))) /* Equivalent hex address = 0x721102d0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115968))) /* Equivalent hex address = 0x72110740UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 56,
    .general.output.dim.tensor_w = 56,
    .general.output.dim.tensor_c = 64,
    .general.output.dim.num_elem = 200704,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 64,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_13 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear7_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 200704);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_11') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_11') start function
static void _ec_blob_cache_start_func_11(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 401408);

};


/* scheduling epoch=12   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_12(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_17 */
  Dequantizelinear_sw_info dequantizelinear8_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 56,
    .general.input.dim.tensor_w = 56,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 401408,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 128,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114576))) /* Equivalent hex address = 0x721101d0UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115712))) /* Equivalent hex address = 0x72110640UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 56,
    .general.output.dim.tensor_w = 56,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 401408,
    .general.output.stride.b = 1605632,
    .general.output.stride.h = 28672,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) /* Equivalent hex address = 0x34100000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_17 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear8_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 11 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 1605632))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) /* Equivalent hex address = 0x34100000UL */, 1605632);

}


/* scheduling epoch=13   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_13(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_18 */
  Activ_sw_info activ9_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 56,
    .general.input.dim.tensor_w = 56,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 401408,
    .general.input.stride.b = 1605632,
    .general.input.stride.h = 28672,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) /* Equivalent hex address = 0x34100000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 129,
    .operand.dim.num_elem = 129,
    .operand.stride.b = 516,
    .operand.stride.h = 516,
    .operand.stride.w = 516,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1106704))) /* Equivalent hex address = 0x7210e310UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 56,
    .general.output.dim.tensor_w = 56,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 401408,
    .general.output.stride.b = 1605632,
    .general.output.stride.h = 28672,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x90000000UL + 0))) /* Equivalent hex address = 0x90000000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_18 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ9_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 7 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x90000000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x90000000UL + 1605632))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x90000000UL + 0))) /* Equivalent hex address = 0x90000000UL */, 1605632);

}


/* scheduling epoch=14   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_14(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_19 */
  Quantizelinear_sw_info quantizelinear10_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 56,
    .general.input.dim.tensor_w = 56,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 401408,
    .general.input.stride.b = 1605632,
    .general.input.stride.h = 28672,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x90000000UL + 0))) /* Equivalent hex address = 0x90000000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114640))) /* Equivalent hex address = 0x72110210UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115776))) /* Equivalent hex address = 0x72110680UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 56,
    .general.output.dim.tensor_w = 56,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 401408,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 7168,
    .general.output.stride.w = 128,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_19 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear10_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 401408);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_15') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_15') start function
static void _ec_blob_cache_start_func_15(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 100352))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 100352);

};


/* scheduling epoch=16   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_16(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_23 */
  Dequantizelinear_sw_info dequantizelinear11_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 128,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114656))) /* Equivalent hex address = 0x72110220UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115792))) /* Equivalent hex address = 0x72110690UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_23 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear11_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 401408);

}


/* scheduling epoch=17   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_17(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_24 */
  Activ_sw_info activ12_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 129,
    .operand.dim.num_elem = 129,
    .operand.stride.b = 516,
    .operand.stride.h = 516,
    .operand.stride.w = 516,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1107232))) /* Equivalent hex address = 0x7210e520UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_24 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ12_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 401408);

}


/* scheduling epoch=18   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_18(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_25 */
  Quantizelinear_sw_info quantizelinear13_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115072))) /* Equivalent hex address = 0x721103c0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116208))) /* Equivalent hex address = 0x72110830UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 128,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_25 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear13_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_19') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_19') start function
static void _ec_blob_cache_start_func_19(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 100352))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 100352);

};


/* scheduling epoch=21   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_21(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_32 */
  Dequantizelinear_sw_info dequantizelinear14_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 128,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114672))) /* Equivalent hex address = 0x72110230UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115808))) /* Equivalent hex address = 0x721106a0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_32 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear14_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 401408);

}


/* scheduling epoch=22   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_22(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_33 */
  Activ_sw_info activ15_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 129,
    .operand.dim.num_elem = 129,
    .operand.stride.b = 516,
    .operand.stride.h = 516,
    .operand.stride.w = 516,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1107760))) /* Equivalent hex address = 0x7210e730UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_33 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ15_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 401408);

}


/* scheduling epoch=23   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_23(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_34 */
  Quantizelinear_sw_info quantizelinear16_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115088))) /* Equivalent hex address = 0x721103d0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116224))) /* Equivalent hex address = 0x72110840UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 128,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_34 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear16_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_24') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_24') start function
static void _ec_blob_cache_start_func_24(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 100352))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 100352);

};


/* scheduling epoch=25   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_25(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_38 */
  Dequantizelinear_sw_info dequantizelinear17_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 128,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114688))) /* Equivalent hex address = 0x72110240UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115824))) /* Equivalent hex address = 0x721106b0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_38 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear17_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 401408);

}


/* scheduling epoch=26   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_26(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_39 */
  Activ_sw_info activ18_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 129,
    .operand.dim.num_elem = 129,
    .operand.stride.b = 516,
    .operand.stride.h = 516,
    .operand.stride.w = 516,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1108288))) /* Equivalent hex address = 0x7210e940UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_39 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ18_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 401408);

}


/* scheduling epoch=27   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_27(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_40 */
  Quantizelinear_sw_info quantizelinear19_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115104))) /* Equivalent hex address = 0x721103e0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116240))) /* Equivalent hex address = 0x72110850UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 128,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_40 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear19_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_28') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_28') start function
static void _ec_blob_cache_start_func_28(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 100352))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 100352);

};


/* scheduling epoch=30   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_30(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_50 */
  Dequantizelinear_sw_info dequantizelinear20_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 128,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114704))) /* Equivalent hex address = 0x72110250UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115840))) /* Equivalent hex address = 0x721106c0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_50 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear20_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 401408);

}


/* scheduling epoch=31   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_31(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_51 */
  Activ_sw_info activ21_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 129,
    .operand.dim.num_elem = 129,
    .operand.stride.b = 516,
    .operand.stride.h = 516,
    .operand.stride.w = 516,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1108816))) /* Equivalent hex address = 0x7210eb50UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_51 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ21_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 401408);

}


/* scheduling epoch=32   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_32(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_52 */
  Quantizelinear_sw_info quantizelinear22_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115120))) /* Equivalent hex address = 0x721103f0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116256))) /* Equivalent hex address = 0x72110860UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 128,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_52 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear22_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_33') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_33') start function
static void _ec_blob_cache_start_func_33(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 100352))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 100352);

};


/* scheduling epoch=34   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_34(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_56 */
  Dequantizelinear_sw_info dequantizelinear23_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 128,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114720))) /* Equivalent hex address = 0x72110260UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115856))) /* Equivalent hex address = 0x721106d0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_56 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear23_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 401408);

}


/* scheduling epoch=35   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_35(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_57 */
  Activ_sw_info activ24_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 129,
    .operand.dim.num_elem = 129,
    .operand.stride.b = 516,
    .operand.stride.h = 516,
    .operand.stride.w = 516,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1109344))) /* Equivalent hex address = 0x7210ed60UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_57 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ24_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 401408);

}


/* scheduling epoch=36   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_36(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_58 */
  Quantizelinear_sw_info quantizelinear25_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115136))) /* Equivalent hex address = 0x72110400UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116272))) /* Equivalent hex address = 0x72110870UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 128,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_58 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear25_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_37') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_37') start function
static void _ec_blob_cache_start_func_37(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 100352))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 100352);

};


/* scheduling epoch=39   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_39(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_68 */
  Dequantizelinear_sw_info dequantizelinear26_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 128,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114736))) /* Equivalent hex address = 0x72110270UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115872))) /* Equivalent hex address = 0x721106e0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_68 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear26_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 401408);

}


/* scheduling epoch=40   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_40(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_69 */
  Activ_sw_info activ27_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 129,
    .operand.dim.num_elem = 129,
    .operand.stride.b = 516,
    .operand.stride.h = 516,
    .operand.stride.w = 516,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1109872))) /* Equivalent hex address = 0x7210ef70UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_69 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ27_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 401408);

}


/* scheduling epoch=41   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_41(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_70 */
  Quantizelinear_sw_info quantizelinear28_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115152))) /* Equivalent hex address = 0x72110410UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116288))) /* Equivalent hex address = 0x72110880UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 128,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_70 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear28_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_42') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_42') start function
static void _ec_blob_cache_start_func_42(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 100352))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 100352);

};


/* scheduling epoch=43   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_43(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_74 */
  Dequantizelinear_sw_info dequantizelinear29_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 128,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114752))) /* Equivalent hex address = 0x72110280UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115888))) /* Equivalent hex address = 0x721106f0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_74 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear29_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 401408);

}


/* scheduling epoch=44   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_44(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_75 */
  Activ_sw_info activ30_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 129,
    .operand.dim.num_elem = 129,
    .operand.stride.b = 516,
    .operand.stride.h = 516,
    .operand.stride.w = 516,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1110400))) /* Equivalent hex address = 0x7210f180UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_75 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ30_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 401408);

}


/* scheduling epoch=45   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_45(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_76 */
  Quantizelinear_sw_info quantizelinear31_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115168))) /* Equivalent hex address = 0x72110420UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116304))) /* Equivalent hex address = 0x72110890UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 128,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_76 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear31_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_46') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_46') start function
static void _ec_blob_cache_start_func_46(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 100352))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 100352);

};


/* scheduling epoch=48   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_48(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_86 */
  Dequantizelinear_sw_info dequantizelinear32_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 128,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114768))) /* Equivalent hex address = 0x72110290UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115904))) /* Equivalent hex address = 0x72110700UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_86 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear32_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 401408);

}


/* scheduling epoch=49   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_49(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_87 */
  Activ_sw_info activ33_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 129,
    .operand.dim.num_elem = 129,
    .operand.stride.b = 516,
    .operand.stride.h = 516,
    .operand.stride.w = 516,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1110928))) /* Equivalent hex address = 0x7210f390UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_87 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ33_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 401408);

}


/* scheduling epoch=50   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_50(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_88 */
  Quantizelinear_sw_info quantizelinear34_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115184))) /* Equivalent hex address = 0x72110430UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116320))) /* Equivalent hex address = 0x721108a0UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 128,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_88 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear34_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_51') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_51') start function
static void _ec_blob_cache_start_func_51(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 100352))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 100352);

};


/* scheduling epoch=52   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_52(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_92 */
  Dequantizelinear_sw_info dequantizelinear35_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 128,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114784))) /* Equivalent hex address = 0x721102a0UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115920))) /* Equivalent hex address = 0x72110710UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_92 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear35_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 401408);

}


/* scheduling epoch=53   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_53(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_93 */
  Activ_sw_info activ36_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 129,
    .operand.dim.num_elem = 129,
    .operand.stride.b = 516,
    .operand.stride.h = 516,
    .operand.stride.w = 516,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1111456))) /* Equivalent hex address = 0x7210f5a0UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_93 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ36_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 401408);

}


/* scheduling epoch=54   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_54(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_94 */
  Quantizelinear_sw_info quantizelinear37_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115200))) /* Equivalent hex address = 0x72110440UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116336))) /* Equivalent hex address = 0x721108b0UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 128,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_94 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear37_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_55') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_55') start function
static void _ec_blob_cache_start_func_55(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

};


/* scheduling epoch=57   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_57(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_104 */
  Dequantizelinear_sw_info dequantizelinear38_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 200704,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114624))) /* Equivalent hex address = 0x72110200UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115760))) /* Equivalent hex address = 0x72110670UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 200704,
    .general.output.stride.b = 802816,
    .general.output.stride.h = 28672,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) /* Equivalent hex address = 0x34100000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_104 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear38_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 11 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 802816))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) /* Equivalent hex address = 0x34100000UL */, 802816);

}


/* scheduling epoch=58   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_58(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_105 */
  Activ_sw_info activ39_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 200704,
    .general.input.stride.b = 802816,
    .general.input.stride.h = 28672,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 0))) /* Equivalent hex address = 0x34100000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1087984))) /* Equivalent hex address = 0x721099f0UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 200704,
    .general.output.stride.b = 802816,
    .general.output.stride.h = 28672,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 802816))) /* Equivalent hex address = 0x341c4000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_105 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ39_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 11 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 802816))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 1605632))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 802816))) /* Equivalent hex address = 0x341c4000UL */, 802816);

}


/* scheduling epoch=59   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_59(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_106 */
  Quantizelinear_sw_info quantizelinear40_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 28,
    .general.input.dim.tensor_w = 28,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 200704,
    .general.input.stride.b = 802816,
    .general.input.stride.h = 28672,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34100000UL + 802816))) /* Equivalent hex address = 0x341c4000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114848))) /* Equivalent hex address = 0x721102e0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115984))) /* Equivalent hex address = 0x72110750UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 28,
    .general.output.dim.tensor_w = 28,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 200704,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 7168,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_106 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear40_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_60') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_60') start function
static void _ec_blob_cache_start_func_60(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 250880))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 50176);

};


/* scheduling epoch=61   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_61(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_110 */
  Dequantizelinear_sw_info dequantizelinear41_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114864))) /* Equivalent hex address = 0x721102f0UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116000))) /* Equivalent hex address = 0x72110760UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_110 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear41_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


/* scheduling epoch=62   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_62(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_111 */
  Activ_sw_info activ42_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1089024))) /* Equivalent hex address = 0x72109e00UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_111 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ42_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

}


/* scheduling epoch=63   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_63(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_112 */
  Quantizelinear_sw_info quantizelinear43_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115312))) /* Equivalent hex address = 0x721104b0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116448))) /* Equivalent hex address = 0x72110920UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_112 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear43_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 451584))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */, 50176);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_64') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_64') start function
static void _ec_blob_cache_start_func_64(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 250880))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 50176);

};


/* scheduling epoch=66   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_66(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_119 */
  Dequantizelinear_sw_info dequantizelinear44_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114880))) /* Equivalent hex address = 0x72110300UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116016))) /* Equivalent hex address = 0x72110770UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_119 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear44_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


/* scheduling epoch=67   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_67(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_120 */
  Activ_sw_info activ45_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1090064))) /* Equivalent hex address = 0x7210a210UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_120 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ45_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

}


/* scheduling epoch=68   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_68(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_121 */
  Quantizelinear_sw_info quantizelinear46_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115328))) /* Equivalent hex address = 0x721104c0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116464))) /* Equivalent hex address = 0x72110930UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_121 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear46_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 451584))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */, 50176);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_69') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_69') start function
static void _ec_blob_cache_start_func_69(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 250880))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 50176);

};


/* scheduling epoch=70   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_70(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_125 */
  Dequantizelinear_sw_info dequantizelinear47_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114896))) /* Equivalent hex address = 0x72110310UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116032))) /* Equivalent hex address = 0x72110780UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_125 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear47_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


/* scheduling epoch=71   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_71(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_126 */
  Activ_sw_info activ48_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1091104))) /* Equivalent hex address = 0x7210a620UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_126 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ48_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

}


/* scheduling epoch=72   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_72(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_127 */
  Quantizelinear_sw_info quantizelinear49_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115344))) /* Equivalent hex address = 0x721104d0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116480))) /* Equivalent hex address = 0x72110940UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_127 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear49_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 451584))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */, 50176);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_73') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_73') start function
static void _ec_blob_cache_start_func_73(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 250880))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 50176);

};


/* scheduling epoch=75   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_75(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_137 */
  Dequantizelinear_sw_info dequantizelinear50_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114912))) /* Equivalent hex address = 0x72110320UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116048))) /* Equivalent hex address = 0x72110790UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_137 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear50_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


/* scheduling epoch=76   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_76(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_138 */
  Activ_sw_info activ51_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1092144))) /* Equivalent hex address = 0x7210aa30UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_138 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ51_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

}


/* scheduling epoch=77   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_77(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_139 */
  Quantizelinear_sw_info quantizelinear52_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115360))) /* Equivalent hex address = 0x721104e0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116496))) /* Equivalent hex address = 0x72110950UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_139 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear52_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 451584))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */, 50176);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_78') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_78') start function
static void _ec_blob_cache_start_func_78(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 250880))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 50176);

};


/* scheduling epoch=79   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_79(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_143 */
  Dequantizelinear_sw_info dequantizelinear53_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114928))) /* Equivalent hex address = 0x72110330UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116064))) /* Equivalent hex address = 0x721107a0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_143 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear53_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


/* scheduling epoch=80   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_80(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_144 */
  Activ_sw_info activ54_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1093184))) /* Equivalent hex address = 0x7210ae40UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_144 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ54_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

}


/* scheduling epoch=81   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_81(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_145 */
  Quantizelinear_sw_info quantizelinear55_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115376))) /* Equivalent hex address = 0x721104f0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116512))) /* Equivalent hex address = 0x72110960UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_145 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear55_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 451584))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */, 50176);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_82') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_82') start function
static void _ec_blob_cache_start_func_82(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 250880))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 50176);

};


/* scheduling epoch=84   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_84(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_155 */
  Dequantizelinear_sw_info dequantizelinear56_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114944))) /* Equivalent hex address = 0x72110340UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116080))) /* Equivalent hex address = 0x721107b0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_155 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear56_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


/* scheduling epoch=85   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_85(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_156 */
  Activ_sw_info activ57_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1094224))) /* Equivalent hex address = 0x7210b250UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_156 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ57_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

}


/* scheduling epoch=86   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_86(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_157 */
  Quantizelinear_sw_info quantizelinear58_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115392))) /* Equivalent hex address = 0x72110500UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116528))) /* Equivalent hex address = 0x72110970UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_157 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear58_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 451584))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */, 50176);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_87') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_87') start function
static void _ec_blob_cache_start_func_87(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 250880))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 50176);

};


/* scheduling epoch=88   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_88(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_161 */
  Dequantizelinear_sw_info dequantizelinear59_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114960))) /* Equivalent hex address = 0x72110350UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116096))) /* Equivalent hex address = 0x721107c0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_161 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear59_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


/* scheduling epoch=89   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_89(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_162 */
  Activ_sw_info activ60_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1095264))) /* Equivalent hex address = 0x7210b660UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_162 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ60_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

}


/* scheduling epoch=90   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_90(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_163 */
  Quantizelinear_sw_info quantizelinear61_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115408))) /* Equivalent hex address = 0x72110510UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116544))) /* Equivalent hex address = 0x72110980UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_163 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear61_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 451584))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */, 50176);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_91') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_91') start function
static void _ec_blob_cache_start_func_91(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 250880))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 50176);

};


/* scheduling epoch=93   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_93(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_173 */
  Dequantizelinear_sw_info dequantizelinear62_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114976))) /* Equivalent hex address = 0x72110360UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116112))) /* Equivalent hex address = 0x721107d0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_173 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear62_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


/* scheduling epoch=94   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_94(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_174 */
  Activ_sw_info activ63_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1096304))) /* Equivalent hex address = 0x7210ba70UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_174 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ63_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

}


/* scheduling epoch=95   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_95(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_175 */
  Quantizelinear_sw_info quantizelinear64_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115424))) /* Equivalent hex address = 0x72110520UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116560))) /* Equivalent hex address = 0x72110990UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_175 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear64_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 451584))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */, 50176);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_96') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_96') start function
static void _ec_blob_cache_start_func_96(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 250880))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 50176);

};


/* scheduling epoch=97   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_97(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_179 */
  Dequantizelinear_sw_info dequantizelinear65_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114992))) /* Equivalent hex address = 0x72110370UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116128))) /* Equivalent hex address = 0x721107e0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_179 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear65_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


/* scheduling epoch=98   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_98(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_180 */
  Activ_sw_info activ66_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1097344))) /* Equivalent hex address = 0x7210be80UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_180 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ66_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

}


/* scheduling epoch=99   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_99(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_181 */
  Quantizelinear_sw_info quantizelinear67_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115440))) /* Equivalent hex address = 0x72110530UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116576))) /* Equivalent hex address = 0x721109a0UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_181 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear67_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 451584))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */, 50176);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_100') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_100') start function
static void _ec_blob_cache_start_func_100(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 250880))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 50176);

};


/* scheduling epoch=102  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_102(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_191 */
  Dequantizelinear_sw_info dequantizelinear68_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115008))) /* Equivalent hex address = 0x72110380UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116144))) /* Equivalent hex address = 0x721107f0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_191 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear68_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


/* scheduling epoch=103  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_103(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_192 */
  Activ_sw_info activ69_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1098384))) /* Equivalent hex address = 0x7210c290UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_192 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ69_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

}


/* scheduling epoch=104  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_104(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_193 */
  Quantizelinear_sw_info quantizelinear70_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115456))) /* Equivalent hex address = 0x72110540UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116592))) /* Equivalent hex address = 0x721109b0UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_193 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear70_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 451584))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */, 50176);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_105') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_105') start function
static void _ec_blob_cache_start_func_105(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 250880))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 50176);

};


/* scheduling epoch=106  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_106(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_197 */
  Dequantizelinear_sw_info dequantizelinear71_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115024))) /* Equivalent hex address = 0x72110390UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116160))) /* Equivalent hex address = 0x72110800UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_197 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear71_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


/* scheduling epoch=107  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_107(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_198 */
  Activ_sw_info activ72_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1099424))) /* Equivalent hex address = 0x7210c6a0UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_198 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ72_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

}


/* scheduling epoch=108  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_108(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_199 */
  Quantizelinear_sw_info quantizelinear73_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115472))) /* Equivalent hex address = 0x72110550UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116608))) /* Equivalent hex address = 0x721109c0UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_199 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear73_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 451584))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */, 50176);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_109') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_109') start function
static void _ec_blob_cache_start_func_109(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 250880))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 50176);

};


/* scheduling epoch=111  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_111(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_209 */
  Dequantizelinear_sw_info dequantizelinear74_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115040))) /* Equivalent hex address = 0x721103a0UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116176))) /* Equivalent hex address = 0x72110810UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_209 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear74_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


/* scheduling epoch=112  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_112(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_210 */
  Activ_sw_info activ75_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1100464))) /* Equivalent hex address = 0x7210cab0UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_210 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ75_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

}


/* scheduling epoch=113  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_113(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_211 */
  Quantizelinear_sw_info quantizelinear76_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115488))) /* Equivalent hex address = 0x72110560UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116624))) /* Equivalent hex address = 0x721109d0UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_211 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear76_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 451584))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */, 50176);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_114') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_114') start function
static void _ec_blob_cache_start_func_114(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 250880))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 50176);

};


/* scheduling epoch=115  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_115(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_215 */
  Dequantizelinear_sw_info dequantizelinear77_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115056))) /* Equivalent hex address = 0x721103b0UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116192))) /* Equivalent hex address = 0x72110820UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_215 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear77_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 200704);

}


/* scheduling epoch=116  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_116(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_216 */
  Activ_sw_info activ78_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1101504))) /* Equivalent hex address = 0x7210cec0UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 200704,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_216 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ78_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */, 200704);

}


/* scheduling epoch=117  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_117(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_217 */
  Quantizelinear_sw_info quantizelinear79_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 50176,
    .general.input.stride.b = 200704,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) /* Equivalent hex address = 0x34311000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115504))) /* Equivalent hex address = 0x72110570UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116640))) /* Equivalent hex address = 0x721109e0UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 50176,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_217 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear79_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 451584))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) /* Equivalent hex address = 0x34342000UL */, 50176);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_118') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_118') start function
static void _ec_blob_cache_start_func_118(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 100352))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 100352);

};


/* scheduling epoch=120  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_120(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_227 */
  Dequantizelinear_sw_info dequantizelinear80_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 512,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1114800))) /* Equivalent hex address = 0x721102b0UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115936))) /* Equivalent hex address = 0x72110720UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 28672,
    .general.output.stride.w = 2048,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_227 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear80_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 401408);

}


/* scheduling epoch=121  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_121(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_228 */
  Activ_sw_info activ81_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 28672,
    .general.input.stride.w = 2048,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 513,
    .operand.dim.num_elem = 513,
    .operand.stride.b = 2052,
    .operand.stride.h = 2052,
    .operand.stride.w = 2052,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1078016))) /* Equivalent hex address = 0x72107300UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 401408,
    .general.output.stride.h = 28672,
    .general.output.stride.w = 2048,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_228 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ81_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 2 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */, 401408);

}


/* scheduling epoch=122  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_122(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_229 */
  Quantizelinear_sw_info quantizelinear82_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 14,
    .general.input.dim.tensor_w = 14,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 100352,
    .general.input.stride.b = 401408,
    .general.input.stride.h = 28672,
    .general.input.stride.w = 2048,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34270000UL + 0))) /* Equivalent hex address = 0x34270000UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115216))) /* Equivalent hex address = 0x72110450UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116352))) /* Equivalent hex address = 0x721108c0UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 14,
    .general.output.dim.tensor_w = 14,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 100352,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 7168,
    .general.output.stride.w = 512,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_229 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear82_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_123') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_123') start function
static void _ec_blob_cache_start_func_123(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 125440))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */, 25088);

};


/* scheduling epoch=124  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_124(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_233 */
  Dequantizelinear_sw_info dequantizelinear83_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 25088,
    .general.input.stride.b = 25088,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 512,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115232))) /* Equivalent hex address = 0x72110460UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116368))) /* Equivalent hex address = 0x721108d0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 25088,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 2048,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_233 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear83_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


/* scheduling epoch=125  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_125(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_234 */
  Activ_sw_info activ84_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 25088,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 2048,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 513,
    .operand.dim.num_elem = 513,
    .operand.stride.b = 2052,
    .operand.stride.h = 2052,
    .operand.stride.w = 2052,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1080080))) /* Equivalent hex address = 0x72107b10UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 25088,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 2048,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_234 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ84_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */, 100352);

}


/* scheduling epoch=126  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_126(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_235 */
  Quantizelinear_sw_info quantizelinear85_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 25088,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 2048,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115600))) /* Equivalent hex address = 0x721105d0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116736))) /* Equivalent hex address = 0x72110a40UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 25088,
    .general.output.stride.b = 25088,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 512,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_235 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear85_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 25088))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 25088);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_127') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_127') start function
static void _ec_blob_cache_start_func_127(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 62720))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */, 12544);

};


/* scheduling epoch=129  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_129(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_242 */
  Dequantizelinear_sw_info dequantizelinear86_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 12544,
    .general.input.stride.b = 12544,
    .general.input.stride.h = 1792,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115520))) /* Equivalent hex address = 0x72110580UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116656))) /* Equivalent hex address = 0x721109f0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 12544,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 7168,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_242 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear86_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 50176);

}


/* scheduling epoch=130  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_130(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_243 */
  Activ_sw_info activ87_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 12544,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1102544))) /* Equivalent hex address = 0x7210d2d0UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 12544,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 7168,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_243 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ87_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */, 50176);

}


/* scheduling epoch=131  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_131(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_244 */
  Quantizelinear_sw_info quantizelinear88_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 12544,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115632))) /* Equivalent hex address = 0x721105f0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116768))) /* Equivalent hex address = 0x72110a60UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 12544,
    .general.output.stride.b = 12544,
    .general.output.stride.h = 1792,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_244 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear88_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 12544))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 12544);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_132') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_132') start function
static void _ec_blob_cache_start_func_132(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 62720))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */, 12544);

};


/* scheduling epoch=133  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_133(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_248 */
  Dequantizelinear_sw_info dequantizelinear89_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 12544,
    .general.input.stride.b = 12544,
    .general.input.stride.h = 1792,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115536))) /* Equivalent hex address = 0x72110590UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116672))) /* Equivalent hex address = 0x72110a00UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 12544,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 7168,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_248 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear89_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 50176);

}


/* scheduling epoch=134  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_134(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_249 */
  Activ_sw_info activ90_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 12544,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1103584))) /* Equivalent hex address = 0x7210d6e0UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 12544,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 7168,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_249 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ90_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */, 50176);

}


/* scheduling epoch=135  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_135(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_250 */
  Quantizelinear_sw_info quantizelinear91_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 12544,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115648))) /* Equivalent hex address = 0x72110600UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116784))) /* Equivalent hex address = 0x72110a70UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 12544,
    .general.output.stride.b = 12544,
    .general.output.stride.h = 1792,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_250 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear91_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 12544))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 12544);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_136') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_136') start function
static void _ec_blob_cache_start_func_136(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 62720))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */, 12544);

};


/* scheduling epoch=138  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_138(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_260 */
  Dequantizelinear_sw_info dequantizelinear92_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 12544,
    .general.input.stride.b = 12544,
    .general.input.stride.h = 1792,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115552))) /* Equivalent hex address = 0x721105a0UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116688))) /* Equivalent hex address = 0x72110a10UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 12544,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 7168,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_260 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear92_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 50176);

}


/* scheduling epoch=139  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_139(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_261 */
  Activ_sw_info activ93_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 12544,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1104624))) /* Equivalent hex address = 0x7210daf0UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 12544,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 7168,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_261 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ93_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */, 50176);

}


/* scheduling epoch=140  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_140(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_262 */
  Quantizelinear_sw_info quantizelinear94_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 12544,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115664))) /* Equivalent hex address = 0x72110610UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116800))) /* Equivalent hex address = 0x72110a80UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 12544,
    .general.output.stride.b = 12544,
    .general.output.stride.h = 1792,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_262 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear94_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 12544))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 12544);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_141') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_141') start function
static void _ec_blob_cache_start_func_141(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 62720))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */, 12544);

};


/* scheduling epoch=142  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_142(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_266 */
  Dequantizelinear_sw_info dequantizelinear95_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 12544,
    .general.input.stride.b = 12544,
    .general.input.stride.h = 1792,
    .general.input.stride.w = 256,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115568))) /* Equivalent hex address = 0x721105b0UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116704))) /* Equivalent hex address = 0x72110a20UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 12544,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 7168,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_266 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear95_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 50176);

}


/* scheduling epoch=143  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_143(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_267 */
  Activ_sw_info activ96_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 12544,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 257,
    .operand.dim.num_elem = 257,
    .operand.stride.b = 1028,
    .operand.stride.h = 1028,
    .operand.stride.w = 1028,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1105664))) /* Equivalent hex address = 0x7210df00UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 12544,
    .general.output.stride.b = 50176,
    .general.output.stride.h = 7168,
    .general.output.stride.w = 1024,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_267 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ96_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */, 50176);

}


/* scheduling epoch=144  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_144(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_268 */
  Quantizelinear_sw_info quantizelinear97_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 256,
    .general.input.dim.num_elem = 12544,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 50176))) /* Equivalent hex address = 0x342ec400UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115680))) /* Equivalent hex address = 0x72110620UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116816))) /* Equivalent hex address = 0x72110a90UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 256,
    .general.output.dim.num_elem = 12544,
    .general.output.stride.b = 12544,
    .general.output.stride.h = 1792,
    .general.output.stride.w = 256,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_268 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear97_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 12544))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 12544);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_145') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_145') start function
static void _ec_blob_cache_start_func_145(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 125440))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */, 25088);

};


/* scheduling epoch=147  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_147(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_278 */
  Dequantizelinear_sw_info dequantizelinear98_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 25088,
    .general.input.stride.b = 25088,
    .general.input.stride.h = 3584,
    .general.input.stride.w = 512,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115248))) /* Equivalent hex address = 0x72110470UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116384))) /* Equivalent hex address = 0x721108e0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 25088,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 2048,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_278 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear98_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


/* scheduling epoch=148  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_148(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=PRelu node=PReLU_279 */
  Activ_sw_info activ99_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 25088,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 2048,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 513,
    .operand.dim.num_elem = 513,
    .operand.stride.b = 2052,
    .operand.stride.h = 2052,
    .operand.stride.w = 2052,
    .operand.stride.c = 4,
    .operand.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1082144))) /* Equivalent hex address = 0x72108320UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 25088,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 2048,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_PRELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node PReLU_279 mapped on EmbedNets (FLOAT) as PRelu | Category: Computational */
  ll_sw_forward_activ(&activ99_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 200704))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */, 100352);

}


/* scheduling epoch=149  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_149(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=QuantizeLinear node=Quantize_280 */
  Quantizelinear_sw_info quantizelinear100_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 25088,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 2048,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */,
    .general.input.format.is_signed = 0,
    /* "os" tensor-related info: */
    .os.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115616))) /* Equivalent hex address = 0x721105e0UL */,
    .os.format.is_signed = 1,
    .os.dim.num_elem = 1,
    /* "ozp" tensor-related info: */
    .ozp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116752))) /* Equivalent hex address = 0x72110a50UL */,
    .ozp.format.is_signed = 1,
    .ozp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 25088,
    .general.output.stride.b = 25088,
    .general.output.stride.h = 3584,
    .general.output.stride.w = 512,
    .general.output.stride.c = 1,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_QUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Quantize_280 mapped on EmbedNets (INTEGER) as QuantizeLinear | Category: Format-Converter */
  ll_sw_forward_quantizelinear(&quantizelinear100_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 25088))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 25088);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_150') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_150') start function
static void _ec_blob_cache_start_func_150(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 150528))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */, 50176);

};


/* scheduling epoch=151  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_151(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=DequantizeLinear_inserted_id1187 */
  Dequantizelinear_sw_info dequantizelinear101_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 25088,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 2,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115264))) /* Equivalent hex address = 0x72110480UL */,
    .is.format.is_signed = 0,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116400))) /* Equivalent hex address = 0x721108f0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 25088,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 2048,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node DequantizeLinear_inserted_id1187 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear101_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


/* scheduling epoch=152  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_152(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Conv node=Conv2D_282_subm_5 */
  Conv_sw_info conv102_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 25088,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 2048,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "weights" tensor-related info: */
    .weights.dim.tensor_b = 512,
    .weights.dim.tensor_h = 1,
    .weights.dim.tensor_w = 1,
    .weights.dim.tensor_c = 1,
    .weights.dim.num_elem = 512,
    .weights.stride.b = 4,
    .weights.stride.h = 4,
    .weights.stride.w = 4,
    .weights.stride.c = 4,
    .weights.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1084208))) /* Equivalent hex address = 0x72108b30UL */,
    .weights.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 512,
    .general.output.stride.b = 2048,
    .general.output.stride.h = 2048,
    .general.output.stride.w = 2048,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 156672))) /* Equivalent hex address = 0x34306400UL */,
    .general.output.format.is_signed = 0,
    /* Node-specific Hyper-parameters: */
    .ngroup = 512,
    .pads = {0, 0, 0, 0},
    .strides = {1, 1},
    .dilations = {1, 1},
    .general.type = LL_SW_CONV,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Conv2D_282_subm_5 mapped on EmbedNets (FLOAT) as Conv | Category: Computational */
  ll_sw_forward_conv(&conv102_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 156672))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 158720))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 156672))) /* Equivalent hex address = 0x34306400UL */, 2048);

}


/* scheduling epoch=153  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_153(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 156672))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 158720))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 156672))) /* Equivalent hex address = 0x34306400UL */, 2048);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Cast node=Cast_inserted_id1192 */
  static const uint32_t Cast_inserted_id1192_tensor_info_in_153__shape_1_512_1_1[] = { 1, 1, 1, 512 };
  static const uint32_t Cast_inserted_id1192_tensor_info_in_153__mem_shape_F_1_512_1_1[] = { 1, 512, 1, 1 };
  static const LL_Buffer_InfoTypeDef Cast_inserted_id1192_tensor_info_in_153[] = {
    {
      .name = "____1171_inserted_in1192",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 156672,
      .offset_end = 158720,
      .offset_limit = 158784,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 153,
      .batch = 512,
      .mem_shape = Cast_inserted_id1192_tensor_info_in_153__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = Cast_inserted_id1192_tensor_info_in_153__shape_1_512_1_1,
    },
    {
      .name = NULL,
    }
  };

  static const uint32_t Cast_inserted_id1192_tensor_info_out_153__shape_1_512_1_1[] = { 1, 1, 1, 512 };
  static const uint32_t Cast_inserted_id1192_tensor_info_out_153__mem_shape_F_1_512_1_1[] = { 1, 512, 1, 1 };
  static const LL_Buffer_InfoTypeDef Cast_inserted_id1192_tensor_info_out_153[] = {
    {
      .name = "____1171_inserted_out1192",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 156672,
      .offset_end = 157696,
      .offset_limit = 157760,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 153,
      .batch = 512,
      .mem_shape = Cast_inserted_id1192_tensor_info_out_153__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = Cast_inserted_id1192_tensor_info_out_153__shape_1_512_1_1,
    },
    {
      .name = NULL,
    }
  };

  LL_ATON_LIB_Cast(Cast_inserted_id1192_tensor_info_in_153, Cast_inserted_id1192_tensor_info_out_153, 0, 1);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 156672))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 158720))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 156672))) /* Equivalent hex address = 0x34306400UL */, 2048);

}


/* scheduling epoch=154  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_154(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=DequantizeLinear_inserted_id1188 */
  Dequantizelinear_sw_info dequantizelinear103_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 25088,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 2,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115280))) /* Equivalent hex address = 0x72110490UL */,
    .is.format.is_signed = 0,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116416))) /* Equivalent hex address = 0x72110900UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 25088,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 2048,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node DequantizeLinear_inserted_id1188 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear103_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


/* scheduling epoch=155  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_155(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Conv node=Conv2D_282_subm_3 */
  Conv_sw_info conv104_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 25088,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 2048,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "weights" tensor-related info: */
    .weights.dim.tensor_b = 512,
    .weights.dim.tensor_h = 3,
    .weights.dim.tensor_w = 1,
    .weights.dim.tensor_c = 1,
    .weights.dim.num_elem = 1536,
    .weights.stride.b = 12,
    .weights.stride.h = 4,
    .weights.stride.w = 4,
    .weights.stride.c = 4,
    .weights.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1043456))) /* Equivalent hex address = 0x720fec00UL */,
    .weights.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 512,
    .general.output.stride.b = 2048,
    .general.output.stride.h = 2048,
    .general.output.stride.w = 2048,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 152576))) /* Equivalent hex address = 0x34305400UL */,
    .general.output.format.is_signed = 0,
    /* Node-specific Hyper-parameters: */
    .ngroup = 512,
    .pads = {0, 0, 0, 0},
    .strides = {1, 1},
    .dilations = {1, 1},
    .general.type = LL_SW_CONV,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Conv2D_282_subm_3 mapped on EmbedNets (FLOAT) as Conv | Category: Computational */
  ll_sw_forward_conv(&conv104_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 152576))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 154624))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 152576))) /* Equivalent hex address = 0x34305400UL */, 2048);

}


/* scheduling epoch=156  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_156(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 152576))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 154624))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 152576))) /* Equivalent hex address = 0x34305400UL */, 2048);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Cast node=Cast_inserted_id1191 */
  static const uint32_t Cast_inserted_id1191_tensor_info_in_156__shape_1_512_1_1[] = { 1, 1, 1, 512 };
  static const uint32_t Cast_inserted_id1191_tensor_info_in_156__mem_shape_F_1_512_1_1[] = { 1, 512, 1, 1 };
  static const LL_Buffer_InfoTypeDef Cast_inserted_id1191_tensor_info_in_156[] = {
    {
      .name = "____1165_inserted_in1191",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 152576,
      .offset_end = 154624,
      .offset_limit = 154688,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 156,
      .batch = 512,
      .mem_shape = Cast_inserted_id1191_tensor_info_in_156__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = Cast_inserted_id1191_tensor_info_in_156__shape_1_512_1_1,
    },
    {
      .name = NULL,
    }
  };

  static const uint32_t Cast_inserted_id1191_tensor_info_out_156__shape_1_512_1_1[] = { 1, 1, 1, 512 };
  static const uint32_t Cast_inserted_id1191_tensor_info_out_156__mem_shape_F_1_512_1_1[] = { 1, 512, 1, 1 };
  static const LL_Buffer_InfoTypeDef Cast_inserted_id1191_tensor_info_out_156[] = {
    {
      .name = "____1165_inserted_out1191",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 152576,
      .offset_end = 153600,
      .offset_limit = 153664,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 156,
      .batch = 512,
      .mem_shape = Cast_inserted_id1191_tensor_info_out_156__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = Cast_inserted_id1191_tensor_info_out_156__shape_1_512_1_1,
    },
    {
      .name = NULL,
    }
  };

  LL_ATON_LIB_Cast(Cast_inserted_id1191_tensor_info_in_156, Cast_inserted_id1191_tensor_info_out_156, 2, 3);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 152576))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 154624))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 152576))) /* Equivalent hex address = 0x34305400UL */, 2048);

}


/* scheduling epoch=157  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_157(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=DequantizeLinear_inserted_id1189 */
  Dequantizelinear_sw_info dequantizelinear105_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 25088,
    .general.input.stride.b = 50176,
    .general.input.stride.h = 7168,
    .general.input.stride.w = 1024,
    .general.input.stride.c = 2,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) /* Equivalent hex address = 0x342f8800UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115296))) /* Equivalent hex address = 0x721104a0UL */,
    .is.format.is_signed = 0,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116432))) /* Equivalent hex address = 0x72110910UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 7,
    .general.output.dim.tensor_w = 7,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 25088,
    .general.output.stride.b = 100352,
    .general.output.stride.h = 14336,
    .general.output.stride.w = 2048,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node DequantizeLinear_inserted_id1189 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear105_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 100352))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 100352);

}


/* scheduling epoch=158  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_158(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Conv node=Conv2D_282_subm_2 */
  Conv_sw_info conv106_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 7,
    .general.input.dim.tensor_w = 7,
    .general.input.dim.tensor_c = 512,
    .general.input.dim.num_elem = 25088,
    .general.input.stride.b = 100352,
    .general.input.stride.h = 14336,
    .general.input.stride.w = 2048,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "weights" tensor-related info: */
    .weights.dim.tensor_b = 512,
    .weights.dim.tensor_h = 3,
    .weights.dim.tensor_w = 1,
    .weights.dim.tensor_c = 1,
    .weights.dim.num_elem = 1536,
    .weights.stride.b = 12,
    .weights.stride.h = 4,
    .weights.stride.w = 4,
    .weights.stride.c = 4,
    .weights.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1037312))) /* Equivalent hex address = 0x720fd400UL */,
    .weights.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 512,
    .general.output.dim.num_elem = 512,
    .general.output.stride.b = 2048,
    .general.output.stride.h = 2048,
    .general.output.stride.w = 2048,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 150528))) /* Equivalent hex address = 0x34304c00UL */,
    .general.output.format.is_signed = 0,
    /* Node-specific Hyper-parameters: */
    .ngroup = 512,
    .pads = {0, 0, 0, 0},
    .strides = {1, 1},
    .dilations = {1, 1},
    .general.type = LL_SW_CONV,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Conv2D_282_subm_2 mapped on EmbedNets (FLOAT) as Conv | Category: Computational */
  ll_sw_forward_conv(&conv106_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 150528))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 152576))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 150528))) /* Equivalent hex address = 0x34304c00UL */, 2048);

}


/* scheduling epoch=159  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_159(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 150528))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 152576))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 150528))) /* Equivalent hex address = 0x34304c00UL */, 2048);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Cast node=Cast_inserted_id1190 */
  static const uint32_t Cast_inserted_id1190_tensor_info_in_159__shape_1_512_1_1[] = { 1, 1, 1, 512 };
  static const uint32_t Cast_inserted_id1190_tensor_info_in_159__mem_shape_F_1_512_1_1[] = { 1, 512, 1, 1 };
  static const LL_Buffer_InfoTypeDef Cast_inserted_id1190_tensor_info_in_159[] = {
    {
      .name = "____1162_inserted_in1190",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 150528,
      .offset_end = 152576,
      .offset_limit = 152640,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 159,
      .batch = 512,
      .mem_shape = Cast_inserted_id1190_tensor_info_in_159__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = Cast_inserted_id1190_tensor_info_in_159__shape_1_512_1_1,
    },
    {
      .name = NULL,
    }
  };

  static const uint32_t Cast_inserted_id1190_tensor_info_out_159__shape_1_512_1_1[] = { 1, 1, 1, 512 };
  static const uint32_t Cast_inserted_id1190_tensor_info_out_159__mem_shape_F_1_512_1_1[] = { 1, 512, 1, 1 };
  static const LL_Buffer_InfoTypeDef Cast_inserted_id1190_tensor_info_out_159[] = {
    {
      .name = "____1162_inserted_out1190",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 150528,
      .offset_end = 151552,
      .offset_limit = 151616,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 159,
      .batch = 512,
      .mem_shape = Cast_inserted_id1190_tensor_info_out_159__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = Cast_inserted_id1190_tensor_info_out_159__shape_1_512_1_1,
    },
    {
      .name = NULL,
    }
  };

  LL_ATON_LIB_Cast(Cast_inserted_id1190_tensor_info_in_159, Cast_inserted_id1190_tensor_info_out_159, 4, 5);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 150528))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 152576))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 150528))) /* Equivalent hex address = 0x34304c00UL */, 2048);

}


// Epoch Controller Blob (name='_ec_blob_face_recognition_160') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_recognition_160') start function
static void _ec_blob_cache_start_func_160(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 128))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 128);

};


/* scheduling epoch=163  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_163(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=DequantizeLinear node=Dequantize_288 */
  Dequantizelinear_sw_info dequantizelinear107_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 128,
    .general.input.stride.b = 128,
    .general.input.stride.h = 128,
    .general.input.stride.w = 1,
    .general.input.stride.c = 1,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 1,
    /* "is" tensor-related info: */
    .is.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1115696))) /* Equivalent hex address = 0x72110630UL */,
    .is.format.is_signed = 1,
    .is.dim.num_elem = 1,
    /* "izp" tensor-related info: */
    .izp.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1116832))) /* Equivalent hex address = 0x72110aa0UL */,
    .izp.format.is_signed = 1,
    .izp.dim.num_elem = 1,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 128,
    .general.output.stride.b = 512,
    .general.output.stride.h = 512,
    .general.output.stride.w = 4,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512))) /* Equivalent hex address = 0x342e0200UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_DEQUANTIZELINEAR,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Dequantize_288 mapped on EmbedNets (INTEGER) as DequantizeLinear | Category: Format-Converter */
  ll_sw_forward_dequantizelinear(&dequantizelinear107_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 1024))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512))) /* Equivalent hex address = 0x342e0200UL */, 512);

}


/* scheduling epoch=164  nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_164(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=BatchNormalization node=BatchNormalization_289 */
  Bn_sw_info bn108_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 128,
    .general.input.stride.b = 512,
    .general.input.stride.h = 512,
    .general.input.stride.w = 4,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512))) /* Equivalent hex address = 0x342e0200UL */,
    .general.input.format.is_signed = 0,
    /* "scale" tensor-related info: */
    .scale.dim.tensor_b = 1,
    .scale.dim.tensor_h = 1,
    .scale.dim.tensor_w = 1,
    .scale.dim.tensor_c = 128,
    .scale.dim.num_elem = 128,
    .scale.stride.b = 512,
    .scale.stride.h = 512,
    .scale.stride.w = 4,
    .scale.stride.c = 4,
    .scale.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1111984))) /* Equivalent hex address = 0x7210f7b0UL */,
    .scale.format.is_signed = 0,
    /* "bias" tensor-related info: */
    .bias.dim.tensor_b = 1,
    .bias.dim.tensor_h = 1,
    .bias.dim.tensor_w = 1,
    .bias.dim.tensor_c = 128,
    .bias.dim.num_elem = 128,
    .bias.stride.b = 512,
    .bias.stride.h = 512,
    .bias.stride.w = 4,
    .bias.stride.c = 4,
    .bias.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1112496))) /* Equivalent hex address = 0x7210f9b0UL */,
    .bias.format.is_signed = 0,
    /* "mean" tensor-related info: */
    .mean.dim.tensor_b = 1,
    .mean.dim.tensor_h = 1,
    .mean.dim.tensor_w = 1,
    .mean.dim.tensor_c = 128,
    .mean.dim.num_elem = 128,
    .mean.stride.b = 512,
    .mean.stride.h = 512,
    .mean.stride.w = 4,
    .mean.stride.c = 4,
    .mean.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1113008))) /* Equivalent hex address = 0x7210fbb0UL */,
    .mean.format.is_signed = 0,
    /* "var" tensor-related info: */
    .var.dim.tensor_b = 1,
    .var.dim.tensor_h = 1,
    .var.dim.tensor_w = 1,
    .var.dim.tensor_c = 128,
    .var.dim.num_elem = 128,
    .var.stride.b = 512,
    .var.stride.h = 512,
    .var.stride.w = 4,
    .var.stride.c = 4,
    .var.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x72000000UL + 1113520))) /* Equivalent hex address = 0x7210fdb0UL */,
    .var.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 128,
    .general.output.stride.b = 512,
    .general.output.stride.h = 512,
    .general.output.stride.w = 4,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = ((unsigned char *)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_BATCHNORM,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node BatchNormalization_289 mapped on EmbedNets (FLOAT) as BatchNormalization | Category: Computational */
  ll_sw_forward_bn(&bn108_sw_info);
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0))) /* Equivalent hex address = 0x342e0000UL */, 512);

}


/* scheduling epoch=165  nodes=1   ------------------------------------------------------------------- */

/* scheduling DONE                 ------------------------------------------------------------------- */

const EpochBlock_ItemTypeDef *LL_ATON_EpochBlockItems_face_recognition(void) {

  static const EpochBlock_ItemTypeDef ll_atonn_rt_epoch_block_array[] = {
    {
      .start_epoch_block = _ec_blob_cache_start_func_1,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_1),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_1 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 1,
      .last_epoch_num = 1,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_2,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 2,
      .last_epoch_num = 2,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_3,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_3),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_3 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 3,
      .last_epoch_num = 3,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_4,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 4,
      .last_epoch_num = 4,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_5,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 5,
      .last_epoch_num = 5,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_6,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 6,
      .last_epoch_num = 6,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_7,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_7),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_7 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 7,
      .last_epoch_num = 7,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_8,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 8,
      .last_epoch_num = 8,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_9,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 9,
      .last_epoch_num = 9,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_10,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 10,
      .last_epoch_num = 10,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_11,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_11),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_11 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 11,
      .last_epoch_num = 11,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_12,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 12,
      .last_epoch_num = 12,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_13,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 13,
      .last_epoch_num = 13,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_14,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 14,
      .last_epoch_num = 14,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_15,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_15),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_15 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 15,
      .last_epoch_num = 15,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_16,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 16,
      .last_epoch_num = 16,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_17,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 17,
      .last_epoch_num = 17,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_18,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 18,
      .last_epoch_num = 18,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_19,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_19),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_19 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 19,
      .last_epoch_num = 20,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_21,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 21,
      .last_epoch_num = 21,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_22,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 22,
      .last_epoch_num = 22,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_23,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 23,
      .last_epoch_num = 23,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_24,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_24),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_24 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 24,
      .last_epoch_num = 24,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_25,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 25,
      .last_epoch_num = 25,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_26,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 26,
      .last_epoch_num = 26,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_27,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 27,
      .last_epoch_num = 27,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_28,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_28),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_28 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 28,
      .last_epoch_num = 29,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_30,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 30,
      .last_epoch_num = 30,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_31,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 31,
      .last_epoch_num = 31,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_32,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 32,
      .last_epoch_num = 32,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_33,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_33),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_33 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 33,
      .last_epoch_num = 33,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_34,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 34,
      .last_epoch_num = 34,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_35,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 35,
      .last_epoch_num = 35,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_36,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 36,
      .last_epoch_num = 36,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_37,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_37),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_37 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 37,
      .last_epoch_num = 38,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_39,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 39,
      .last_epoch_num = 39,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_40,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 40,
      .last_epoch_num = 40,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_41,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 41,
      .last_epoch_num = 41,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_42,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_42),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_42 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 42,
      .last_epoch_num = 42,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_43,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 43,
      .last_epoch_num = 43,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_44,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 44,
      .last_epoch_num = 44,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_45,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 45,
      .last_epoch_num = 45,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_46,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_46),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_46 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 46,
      .last_epoch_num = 47,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_48,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 48,
      .last_epoch_num = 48,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_49,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 49,
      .last_epoch_num = 49,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_50,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 50,
      .last_epoch_num = 50,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_51,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_51),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_51 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 51,
      .last_epoch_num = 51,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_52,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 52,
      .last_epoch_num = 52,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_53,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 53,
      .last_epoch_num = 53,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_54,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 54,
      .last_epoch_num = 54,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_55,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_55),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_55 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 55,
      .last_epoch_num = 56,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_57,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 57,
      .last_epoch_num = 57,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_58,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 58,
      .last_epoch_num = 58,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_59,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 59,
      .last_epoch_num = 59,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_60,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_60),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_60 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 60,
      .last_epoch_num = 60,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_61,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 61,
      .last_epoch_num = 61,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_62,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 62,
      .last_epoch_num = 62,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_63,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 63,
      .last_epoch_num = 63,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_64,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_64),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_64 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 64,
      .last_epoch_num = 65,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_66,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 66,
      .last_epoch_num = 66,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_67,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 67,
      .last_epoch_num = 67,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_68,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 68,
      .last_epoch_num = 68,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_69,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_69),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_69 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 69,
      .last_epoch_num = 69,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_70,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 70,
      .last_epoch_num = 70,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_71,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 71,
      .last_epoch_num = 71,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_72,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 72,
      .last_epoch_num = 72,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_73,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_73),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_73 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 73,
      .last_epoch_num = 74,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_75,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 75,
      .last_epoch_num = 75,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_76,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 76,
      .last_epoch_num = 76,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_77,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 77,
      .last_epoch_num = 77,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_78,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_78),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_78 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 78,
      .last_epoch_num = 78,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_79,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 79,
      .last_epoch_num = 79,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_80,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 80,
      .last_epoch_num = 80,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_81,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 81,
      .last_epoch_num = 81,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_82,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_82),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_82 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 82,
      .last_epoch_num = 83,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_84,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 84,
      .last_epoch_num = 84,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_85,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 85,
      .last_epoch_num = 85,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_86,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 86,
      .last_epoch_num = 86,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_87,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_87),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_87 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 87,
      .last_epoch_num = 87,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_88,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 88,
      .last_epoch_num = 88,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_89,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 89,
      .last_epoch_num = 89,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_90,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 90,
      .last_epoch_num = 90,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_91,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_91),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_91 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 91,
      .last_epoch_num = 92,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_93,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 93,
      .last_epoch_num = 93,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_94,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 94,
      .last_epoch_num = 94,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_95,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 95,
      .last_epoch_num = 95,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_96,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_96),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_96 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 96,
      .last_epoch_num = 96,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_97,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 97,
      .last_epoch_num = 97,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_98,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 98,
      .last_epoch_num = 98,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_99,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 99,
      .last_epoch_num = 99,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_100,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_100),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_100 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 100,
      .last_epoch_num = 101,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_102,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 102,
      .last_epoch_num = 102,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_103,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 103,
      .last_epoch_num = 103,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_104,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 104,
      .last_epoch_num = 104,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_105,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_105),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_105 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 105,
      .last_epoch_num = 105,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_106,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 106,
      .last_epoch_num = 106,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_107,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 107,
      .last_epoch_num = 107,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_108,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 108,
      .last_epoch_num = 108,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_109,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_109),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_109 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 109,
      .last_epoch_num = 110,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_111,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 111,
      .last_epoch_num = 111,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_112,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 112,
      .last_epoch_num = 112,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_113,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 113,
      .last_epoch_num = 113,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_114,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_114),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_114 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 114,
      .last_epoch_num = 114,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_115,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 115,
      .last_epoch_num = 115,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_116,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 116,
      .last_epoch_num = 116,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_117,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 117,
      .last_epoch_num = 117,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_118,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_118),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_118 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 118,
      .last_epoch_num = 119,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_120,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 120,
      .last_epoch_num = 120,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_121,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 121,
      .last_epoch_num = 121,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_122,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 122,
      .last_epoch_num = 122,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_123,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_123),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_123 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 123,
      .last_epoch_num = 123,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_124,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 124,
      .last_epoch_num = 124,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_125,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 125,
      .last_epoch_num = 125,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_126,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 126,
      .last_epoch_num = 126,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_127,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_127),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_127 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 127,
      .last_epoch_num = 128,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_129,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 129,
      .last_epoch_num = 129,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_130,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 130,
      .last_epoch_num = 130,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_131,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 131,
      .last_epoch_num = 131,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_132,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_132),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_132 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 132,
      .last_epoch_num = 132,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_133,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 133,
      .last_epoch_num = 133,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_134,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 134,
      .last_epoch_num = 134,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_135,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 135,
      .last_epoch_num = 135,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_136,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_136),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_136 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 136,
      .last_epoch_num = 137,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_138,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 138,
      .last_epoch_num = 138,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_139,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 139,
      .last_epoch_num = 139,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_140,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 140,
      .last_epoch_num = 140,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_141,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_141),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_141 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 141,
      .last_epoch_num = 141,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_142,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 142,
      .last_epoch_num = 142,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_143,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 143,
      .last_epoch_num = 143,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_144,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 144,
      .last_epoch_num = 144,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_145,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_145),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_145 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 145,
      .last_epoch_num = 146,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_147,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 147,
      .last_epoch_num = 147,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_148,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 148,
      .last_epoch_num = 148,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_149,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 149,
      .last_epoch_num = 149,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_150,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_150),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_150 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 150,
      .last_epoch_num = 150,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_151,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 151,
      .last_epoch_num = 151,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_152,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 152,
      .last_epoch_num = 152,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_153,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 153,
      .last_epoch_num = 153,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_154,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 154,
      .last_epoch_num = 154,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_155,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 155,
      .last_epoch_num = 155,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_156,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 156,
      .last_epoch_num = 156,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_157,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 157,
      .last_epoch_num = 157,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_158,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 158,
      .last_epoch_num = 158,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_159,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 159,
      .last_epoch_num = 159,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_160,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_recognition_160),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_recognition__ec_blob_face_recognition_160 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 160,
      .last_epoch_num = 162,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_163,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 163,
      .last_epoch_num = 163,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_164,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 164,
      .last_epoch_num = 164,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .flags = EpochBlock_Flags_last_eb,
    },
  };


  return ll_atonn_rt_epoch_block_array;
}

const LL_Buffer_InfoTypeDef *LL_ATON_Input_Buffers_Info_face_recognition(void)
{
  static const uint32_t buff_info__shape_1_3_112_112[] = { 1, 112, 112, 3 };
  static const uint32_t buff_info__mem_shape_F_1_3_112_112[] = { 1, 3, 112, 112 };
#if LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
  static const uint32_t buff_info__shape_1[] = { 1, 1, 1, 1 };
  static const uint32_t buff_info__mem_shape_U_1[] = { 1 };
  static const uint32_t buff_info__shape_64_3_3_3[] = { 64, 3, 3, 3 };
  static const uint32_t buff_info__mem_shape_L_64_3_3_3[] = { 64, 3, 3, 3 };
  static const float buff_info_Conv2D_3_weights_quant_scale[] = { 0.00446182815358043 };
  static const int16_t buff_info_Conv2D_3_weights_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_128_64_1_1[] = { 128, 1, 1, 64 };
  static const uint32_t buff_info__mem_shape_M16_128_64_1_1[] = { 128, 4, 1, 1, 16 };
  static const float buff_info_Conv2D_15_weights_quant_scale[] = { 0.0194538161158562 };
  static const int16_t buff_info_Conv2D_15_weights_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_64_128_1_1[] = { 64, 1, 1, 128 };
  static const uint32_t buff_info__mem_shape_M16_64_128_1_1[] = { 64, 8, 1, 1, 16 };
  static const float buff_info_Conv2D_27_weights_quant_scale[] = { 0.0131332883611321 };
  static const int16_t buff_info_Conv2D_27_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_30_weights_quant_scale[] = { 0.00507751107215881 };
  static const int16_t buff_info_Conv2D_30_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_42_weights_quant_scale[] = { 0.0114418361335993 };
  static const int16_t buff_info_Conv2D_42_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_48_weights_quant_scale[] = { 0.00541859492659569 };
  static const int16_t buff_info_Conv2D_48_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_60_weights_quant_scale[] = { 0.0133299436420202 };
  static const int16_t buff_info_Conv2D_60_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_66_weights_quant_scale[] = { 0.00467363651841879 };
  static const int16_t buff_info_Conv2D_66_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_78_weights_quant_scale[] = { 0.0195369459688663 };
  static const int16_t buff_info_Conv2D_78_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_84_weights_quant_scale[] = { 0.00303967413492501 };
  static const int16_t buff_info_Conv2D_84_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_96_weights_quant_scale[] = { 0.0339591465890408 };
  static const int16_t buff_info_Conv2D_96_weights_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_256_64_1_1[] = { 256, 1, 1, 64 };
  static const uint32_t buff_info__mem_shape_M16_256_64_1_1[] = { 256, 4, 1, 1, 16 };
  static const float buff_info_Conv2D_102_weights_quant_scale[] = { 0.00558423018082976 };
  static const int16_t buff_info_Conv2D_102_weights_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_128_256_1_1[] = { 128, 1, 1, 256 };
  static const uint32_t buff_info__mem_shape_M16_128_256_1_1[] = { 128, 16, 1, 1, 16 };
  static const float buff_info_Conv2D_114_weights_quant_scale[] = { 0.00911753717809916 };
  static const int16_t buff_info_Conv2D_114_weights_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_256_128_1_1[] = { 256, 1, 1, 128 };
  static const uint32_t buff_info__mem_shape_M16_256_128_1_1[] = { 256, 8, 1, 1, 16 };
  static const float buff_info_Conv2D_117_weights_quant_scale[] = { 0.00238036457449198 };
  static const int16_t buff_info_Conv2D_117_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_129_weights_quant_scale[] = { 0.0126139707863331 };
  static const int16_t buff_info_Conv2D_129_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_135_weights_quant_scale[] = { 0.00285317632369697 };
  static const int16_t buff_info_Conv2D_135_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_147_weights_quant_scale[] = { 0.0175942834466696 };
  static const int16_t buff_info_Conv2D_147_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_153_weights_quant_scale[] = { 0.00390553520992398 };
  static const int16_t buff_info_Conv2D_153_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_165_weights_quant_scale[] = { 0.0159611441195011 };
  static const int16_t buff_info_Conv2D_165_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_171_weights_quant_scale[] = { 0.00274573918431997 };
  static const int16_t buff_info_Conv2D_171_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_183_weights_quant_scale[] = { 0.0219177324324846 };
  static const int16_t buff_info_Conv2D_183_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_189_weights_quant_scale[] = { 0.00241998746059835 };
  static const int16_t buff_info_Conv2D_189_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_201_weights_quant_scale[] = { 0.0231832936406136 };
  static const int16_t buff_info_Conv2D_201_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_207_weights_quant_scale[] = { 0.00212446856312454 };
  static const int16_t buff_info_Conv2D_207_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_219_weights_quant_scale[] = { 0.0236117728054523 };
  static const int16_t buff_info_Conv2D_219_weights_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_512_128_1_1[] = { 512, 1, 1, 128 };
  static const uint32_t buff_info__mem_shape_M16_512_128_1_1[] = { 512, 8, 1, 1, 16 };
  static const float buff_info_Conv2D_225_weights_quant_scale[] = { 0.00242899334989488 };
  static const int16_t buff_info_Conv2D_225_weights_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_128_512_1_1[] = { 128, 1, 1, 512 };
  static const uint32_t buff_info__mem_shape_M16_128_512_1_1[] = { 128, 32, 1, 1, 16 };
  static const float buff_info_Conv2D_237_weights_quant_scale[] = { 0.0120049640536308 };
  static const int16_t buff_info_Conv2D_237_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_240_weights_quant_scale[] = { 0.00713786343112588 };
  static const int16_t buff_info_Conv2D_240_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_252_weights_quant_scale[] = { 0.0217841602861881 };
  static const int16_t buff_info_Conv2D_252_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_258_weights_quant_scale[] = { 0.0055674621835351 };
  static const int16_t buff_info_Conv2D_258_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_270_weights_quant_scale[] = { 0.0252644252032042 };
  static const int16_t buff_info_Conv2D_270_weights_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_276_weights_quant_scale[] = { 0.0054029687307775 };
  static const int16_t buff_info_Conv2D_276_weights_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_128[] = { 1, 1, 128, 1 };
  static const uint32_t buff_info__mem_shape_U_128[] = { 128 };
  static const float buff_info_Gemm_286_weights_transposed_3_quant_scale[] = { 0.004392612259835 };
  static const int16_t buff_info_Gemm_286_weights_transposed_3_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_64_4_3_3[] = { 64, 3, 3, 4 };
  static const uint32_t buff_info__mem_shape_L_64_4_3_3[] = { 64, 3, 3, 4 };
  static const float buff_info_Conv2D_9_weights_inflated_454_quant_scale[] = { 0.233241707086563 };
  static const int16_t buff_info_Conv2D_9_weights_inflated_454_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_128_4_3_3[] = { 128, 3, 3, 4 };
  static const uint32_t buff_info__mem_shape_L_128_4_3_3[] = { 128, 3, 3, 4 };
  static const float buff_info_Conv2D_21_weights_inflated_456_quant_scale[] = { 0.0717299804091454 };
  static const int16_t buff_info_Conv2D_21_weights_inflated_456_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_36_weights_inflated_458_quant_scale[] = { 0.170400694012642 };
  static const int16_t buff_info_Conv2D_36_weights_inflated_458_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_54_weights_inflated_460_quant_scale[] = { 0.167321547865868 };
  static const int16_t buff_info_Conv2D_54_weights_inflated_460_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_72_weights_inflated_462_quant_scale[] = { 0.133443638682365 };
  static const int16_t buff_info_Conv2D_72_weights_inflated_462_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_90_weights_inflated_464_quant_scale[] = { 0.191192969679832 };
  static const int16_t buff_info_Conv2D_90_weights_inflated_464_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_256_4_3_3[] = { 256, 3, 3, 4 };
  static const uint32_t buff_info__mem_shape_L_256_4_3_3[] = { 256, 3, 3, 4 };
  static const float buff_info_Conv2D_108_weights_inflated_466_quant_scale[] = { 0.0874975621700287 };
  static const int16_t buff_info_Conv2D_108_weights_inflated_466_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_123_weights_inflated_468_quant_scale[] = { 0.13650369644165 };
  static const int16_t buff_info_Conv2D_123_weights_inflated_468_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_141_weights_inflated_470_quant_scale[] = { 0.141305819153786 };
  static const int16_t buff_info_Conv2D_141_weights_inflated_470_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_159_weights_inflated_472_quant_scale[] = { 0.155911728739738 };
  static const int16_t buff_info_Conv2D_159_weights_inflated_472_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_177_weights_inflated_474_quant_scale[] = { 0.117918685078621 };
  static const int16_t buff_info_Conv2D_177_weights_inflated_474_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_195_weights_inflated_476_quant_scale[] = { 0.136549323797226 };
  static const int16_t buff_info_Conv2D_195_weights_inflated_476_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_213_weights_inflated_478_quant_scale[] = { 0.171846181154251 };
  static const int16_t buff_info_Conv2D_213_weights_inflated_478_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_512_4_3_3[] = { 512, 3, 3, 4 };
  static const uint32_t buff_info__mem_shape_L_512_4_3_3[] = { 512, 3, 3, 4 };
  static const float buff_info_Conv2D_231_weights_inflated_480_quant_scale[] = { 0.0948069244623184 };
  static const int16_t buff_info_Conv2D_231_weights_inflated_480_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_246_weights_inflated_482_quant_scale[] = { 0.118711099028587 };
  static const int16_t buff_info_Conv2D_246_weights_inflated_482_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_264_weights_inflated_484_quant_scale[] = { 0.121260710060596 };
  static const int16_t buff_info_Conv2D_264_weights_inflated_484_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_512_1_3_6[] = { 512, 3, 6, 1 };
  static const uint32_t buff_info__mem_shape_F_512_1_3_6[] = { 512, 1, 3, 6 };
  static const float buff_info_Conv2D_282_weights_submask_0_0_0_0_512_1_3_6_486_quant_scale[] = { 0.33640256524086 };
  static const int16_t buff_info_Conv2D_282_weights_submask_0_0_0_0_512_1_3_6_486_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_282_weights_submask_0_0_3_0_512_1_3_6_487_quant_scale[] = { 0.33640256524086 };
  static const int16_t buff_info_Conv2D_282_weights_submask_0_0_3_0_512_1_3_6_487_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_512_1_3_1[] = { 512, 3, 1, 1 };
  static const uint32_t buff_info__mem_shape_F_512_1_3_1[] = { 512, 1, 3, 1 };
  static const uint32_t buff_info__shape_512_1_1_6[] = { 512, 1, 6, 1 };
  static const uint32_t buff_info__mem_shape_F_512_1_1_6[] = { 512, 1, 1, 6 };
  static const float buff_info_Conv2D_282_weights_submask_0_0_6_0_512_1_1_6_490_quant_scale[] = { 0.33640256524086 };
  static const int16_t buff_info_Conv2D_282_weights_submask_0_0_6_0_512_1_1_6_490_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_512_1_1_1[] = { 512, 1, 1, 1 };
  static const uint32_t buff_info__mem_shape_F_512_1_1_1[] = { 512, 1, 1, 1 };
  static const uint32_t buff_info__shape_1_65_1_1[] = { 1, 1, 1, 65 };
  static const uint32_t buff_info__mem_shape_F_1_65_1_1[] = { 1, 65, 1, 1 };
  static const uint32_t buff_info__shape_1_129_1_1[] = { 1, 1, 1, 129 };
  static const uint32_t buff_info__mem_shape_F_1_129_1_1[] = { 1, 129, 1, 1 };
  static const uint32_t buff_info__shape_1_257_1_1[] = { 1, 1, 1, 257 };
  static const uint32_t buff_info__mem_shape_F_1_257_1_1[] = { 1, 257, 1, 1 };
  static const uint32_t buff_info__shape_1_513_1_1[] = { 1, 1, 1, 513 };
  static const uint32_t buff_info__mem_shape_F_1_513_1_1[] = { 1, 513, 1, 1 };
#endif // LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
  static const LL_Buffer_InfoTypeDef buff_info[] = {
    {
      .name = "Input_0_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 150528,
      .offset_limit = 150592,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_3_112_112,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_3_112_112,
    },
#if LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
    {
      .name = "Quantize_1_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115584,
      .offset_end = 1115588,
      .offset_limit = 1115656,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_1_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116720,
      .offset_end = 1116721,
      .offset_limit = 1116792,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_3_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1086256,
      .offset_end = 1087984,
      .offset_limit = 1088048,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 3,
      .mem_shape = buff_info__mem_shape_L_64_3_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_64_3_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_3_weights_quant_scale,
      .offset = buff_info_Conv2D_3_weights_quant_offset,
    },
    {
      .name = "Dequantize_5_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114592,
      .offset_end = 1114596,
      .offset_limit = 1114664,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_5_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115728,
      .offset_end = 1115729,
      .offset_limit = 1115800,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_7_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114816,
      .offset_end = 1114820,
      .offset_limit = 1114888,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_7_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115952,
      .offset_end = 1115953,
      .offset_limit = 1116024,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_11_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114608,
      .offset_end = 1114612,
      .offset_limit = 1114680,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_11_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115744,
      .offset_end = 1115745,
      .offset_limit = 1115816,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_13_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114832,
      .offset_end = 1114836,
      .offset_limit = 1114904,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_13_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115968,
      .offset_end = 1115969,
      .offset_limit = 1116040,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_15_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 996352,
      .offset_end = 1004544,
      .offset_limit = 1004608,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_64_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_64_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_15_weights_quant_scale,
      .offset = buff_info_Conv2D_15_weights_quant_offset,
    },
    {
      .name = "Dequantize_17_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114576,
      .offset_end = 1114580,
      .offset_limit = 1114648,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_17_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115712,
      .offset_end = 1115713,
      .offset_limit = 1115784,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_19_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114640,
      .offset_end = 1114644,
      .offset_limit = 1114712,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_19_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115776,
      .offset_end = 1115777,
      .offset_limit = 1115848,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_23_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114656,
      .offset_end = 1114660,
      .offset_limit = 1114728,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_23_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115792,
      .offset_end = 1115793,
      .offset_limit = 1115864,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_25_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115072,
      .offset_end = 1115076,
      .offset_limit = 1115144,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_25_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116208,
      .offset_end = 1116209,
      .offset_limit = 1116280,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_27_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 955392,
      .offset_end = 963584,
      .offset_limit = 963648,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_64_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_64_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_27_weights_quant_scale,
      .offset = buff_info_Conv2D_27_weights_quant_offset,
    },
    {
      .name = "Conv2D_30_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1004544,
      .offset_end = 1012736,
      .offset_limit = 1012800,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_64_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_64_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_30_weights_quant_scale,
      .offset = buff_info_Conv2D_30_weights_quant_offset,
    },
    {
      .name = "Dequantize_32_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114672,
      .offset_end = 1114676,
      .offset_limit = 1114744,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_32_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115808,
      .offset_end = 1115809,
      .offset_limit = 1115880,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_34_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115088,
      .offset_end = 1115092,
      .offset_limit = 1115160,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_34_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116224,
      .offset_end = 1116225,
      .offset_limit = 1116296,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_38_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114688,
      .offset_end = 1114692,
      .offset_limit = 1114760,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_38_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115824,
      .offset_end = 1115825,
      .offset_limit = 1115896,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_40_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115104,
      .offset_end = 1115108,
      .offset_limit = 1115176,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_40_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116240,
      .offset_end = 1116241,
      .offset_limit = 1116312,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_42_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 963584,
      .offset_end = 971776,
      .offset_limit = 971840,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_64_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_64_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_42_weights_quant_scale,
      .offset = buff_info_Conv2D_42_weights_quant_offset,
    },
    {
      .name = "Conv2D_48_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1012736,
      .offset_end = 1020928,
      .offset_limit = 1020992,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_64_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_64_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_48_weights_quant_scale,
      .offset = buff_info_Conv2D_48_weights_quant_offset,
    },
    {
      .name = "Dequantize_50_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114704,
      .offset_end = 1114708,
      .offset_limit = 1114776,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_50_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115840,
      .offset_end = 1115841,
      .offset_limit = 1115912,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_52_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115120,
      .offset_end = 1115124,
      .offset_limit = 1115192,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_52_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116256,
      .offset_end = 1116257,
      .offset_limit = 1116328,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_56_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114720,
      .offset_end = 1114724,
      .offset_limit = 1114792,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_56_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115856,
      .offset_end = 1115857,
      .offset_limit = 1115928,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_58_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115136,
      .offset_end = 1115140,
      .offset_limit = 1115208,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_58_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116272,
      .offset_end = 1116273,
      .offset_limit = 1116344,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_60_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 971776,
      .offset_end = 979968,
      .offset_limit = 980032,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_64_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_64_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_60_weights_quant_scale,
      .offset = buff_info_Conv2D_60_weights_quant_offset,
    },
    {
      .name = "Conv2D_66_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1020928,
      .offset_end = 1029120,
      .offset_limit = 1029184,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_64_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_64_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_66_weights_quant_scale,
      .offset = buff_info_Conv2D_66_weights_quant_offset,
    },
    {
      .name = "Dequantize_68_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114736,
      .offset_end = 1114740,
      .offset_limit = 1114808,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_68_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115872,
      .offset_end = 1115873,
      .offset_limit = 1115944,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_70_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115152,
      .offset_end = 1115156,
      .offset_limit = 1115224,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_70_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116288,
      .offset_end = 1116289,
      .offset_limit = 1116360,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_74_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114752,
      .offset_end = 1114756,
      .offset_limit = 1114824,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_74_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115888,
      .offset_end = 1115889,
      .offset_limit = 1115960,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_76_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115168,
      .offset_end = 1115172,
      .offset_limit = 1115240,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_76_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116304,
      .offset_end = 1116305,
      .offset_limit = 1116376,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_78_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 979968,
      .offset_end = 988160,
      .offset_limit = 988224,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_64_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_64_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_78_weights_quant_scale,
      .offset = buff_info_Conv2D_78_weights_quant_offset,
    },
    {
      .name = "Conv2D_84_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1029120,
      .offset_end = 1037312,
      .offset_limit = 1037376,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_64_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_64_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_84_weights_quant_scale,
      .offset = buff_info_Conv2D_84_weights_quant_offset,
    },
    {
      .name = "Dequantize_86_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114768,
      .offset_end = 1114772,
      .offset_limit = 1114840,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_86_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115904,
      .offset_end = 1115905,
      .offset_limit = 1115976,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_88_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115184,
      .offset_end = 1115188,
      .offset_limit = 1115256,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_88_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116320,
      .offset_end = 1116321,
      .offset_limit = 1116392,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_92_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114784,
      .offset_end = 1114788,
      .offset_limit = 1114856,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_92_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115920,
      .offset_end = 1115921,
      .offset_limit = 1115992,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_94_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115200,
      .offset_end = 1115204,
      .offset_limit = 1115272,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_94_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116336,
      .offset_end = 1116337,
      .offset_limit = 1116408,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_96_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 988160,
      .offset_end = 996352,
      .offset_limit = 996416,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_64_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_64_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_96_weights_quant_scale,
      .offset = buff_info_Conv2D_96_weights_quant_offset,
    },
    {
      .name = "Conv2D_102_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 837632,
      .offset_end = 854016,
      .offset_limit = 854080,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_256_64_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_64_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_102_weights_quant_scale,
      .offset = buff_info_Conv2D_102_weights_quant_offset,
    },
    {
      .name = "Dequantize_104_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114624,
      .offset_end = 1114628,
      .offset_limit = 1114696,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_104_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115760,
      .offset_end = 1115761,
      .offset_limit = 1115832,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_106_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114848,
      .offset_end = 1114852,
      .offset_limit = 1114920,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_106_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115984,
      .offset_end = 1115985,
      .offset_limit = 1116056,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_110_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114864,
      .offset_end = 1114868,
      .offset_limit = 1114936,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_110_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116000,
      .offset_end = 1116001,
      .offset_limit = 1116072,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_112_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115312,
      .offset_end = 1115316,
      .offset_limit = 1115384,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_112_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116448,
      .offset_end = 1116449,
      .offset_limit = 1116520,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_114_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 262144,
      .offset_end = 294912,
      .offset_limit = 294976,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_256_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_256_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_114_weights_quant_scale,
      .offset = buff_info_Conv2D_114_weights_quant_offset,
    },
    {
      .name = "Conv2D_117_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 294912,
      .offset_end = 327680,
      .offset_limit = 327744,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_256_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_117_weights_quant_scale,
      .offset = buff_info_Conv2D_117_weights_quant_offset,
    },
    {
      .name = "Dequantize_119_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114880,
      .offset_end = 1114884,
      .offset_limit = 1114952,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_119_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116016,
      .offset_end = 1116017,
      .offset_limit = 1116088,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_121_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115328,
      .offset_end = 1115332,
      .offset_limit = 1115400,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_121_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116464,
      .offset_end = 1116465,
      .offset_limit = 1116536,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_125_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114896,
      .offset_end = 1114900,
      .offset_limit = 1114968,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_125_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116032,
      .offset_end = 1116033,
      .offset_limit = 1116104,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_127_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115344,
      .offset_end = 1115348,
      .offset_limit = 1115416,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_127_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116480,
      .offset_end = 1116481,
      .offset_limit = 1116552,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_129_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 327680,
      .offset_end = 360448,
      .offset_limit = 360512,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_256_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_256_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_129_weights_quant_scale,
      .offset = buff_info_Conv2D_129_weights_quant_offset,
    },
    {
      .name = "Conv2D_135_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 360448,
      .offset_end = 393216,
      .offset_limit = 393280,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_256_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_135_weights_quant_scale,
      .offset = buff_info_Conv2D_135_weights_quant_offset,
    },
    {
      .name = "Dequantize_137_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114912,
      .offset_end = 1114916,
      .offset_limit = 1114984,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_137_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116048,
      .offset_end = 1116049,
      .offset_limit = 1116120,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_139_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115360,
      .offset_end = 1115364,
      .offset_limit = 1115432,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_139_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116496,
      .offset_end = 1116497,
      .offset_limit = 1116568,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_143_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114928,
      .offset_end = 1114932,
      .offset_limit = 1115000,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_143_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116064,
      .offset_end = 1116065,
      .offset_limit = 1116136,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_145_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115376,
      .offset_end = 1115380,
      .offset_limit = 1115448,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_145_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116512,
      .offset_end = 1116513,
      .offset_limit = 1116584,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_147_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 393216,
      .offset_end = 425984,
      .offset_limit = 426048,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_256_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_256_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_147_weights_quant_scale,
      .offset = buff_info_Conv2D_147_weights_quant_offset,
    },
    {
      .name = "Conv2D_153_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 425984,
      .offset_end = 458752,
      .offset_limit = 458816,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_256_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_153_weights_quant_scale,
      .offset = buff_info_Conv2D_153_weights_quant_offset,
    },
    {
      .name = "Dequantize_155_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114944,
      .offset_end = 1114948,
      .offset_limit = 1115016,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_155_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116080,
      .offset_end = 1116081,
      .offset_limit = 1116152,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_157_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115392,
      .offset_end = 1115396,
      .offset_limit = 1115464,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_157_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116528,
      .offset_end = 1116529,
      .offset_limit = 1116600,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_161_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114960,
      .offset_end = 1114964,
      .offset_limit = 1115032,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_161_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116096,
      .offset_end = 1116097,
      .offset_limit = 1116168,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_163_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115408,
      .offset_end = 1115412,
      .offset_limit = 1115480,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_163_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116544,
      .offset_end = 1116545,
      .offset_limit = 1116616,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_165_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 458752,
      .offset_end = 491520,
      .offset_limit = 491584,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_256_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_256_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_165_weights_quant_scale,
      .offset = buff_info_Conv2D_165_weights_quant_offset,
    },
    {
      .name = "Conv2D_171_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 491520,
      .offset_end = 524288,
      .offset_limit = 524352,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_256_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_171_weights_quant_scale,
      .offset = buff_info_Conv2D_171_weights_quant_offset,
    },
    {
      .name = "Dequantize_173_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114976,
      .offset_end = 1114980,
      .offset_limit = 1115048,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_173_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116112,
      .offset_end = 1116113,
      .offset_limit = 1116184,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_175_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115424,
      .offset_end = 1115428,
      .offset_limit = 1115496,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_175_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116560,
      .offset_end = 1116561,
      .offset_limit = 1116632,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_179_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114992,
      .offset_end = 1114996,
      .offset_limit = 1115064,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_179_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116128,
      .offset_end = 1116129,
      .offset_limit = 1116200,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_181_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115440,
      .offset_end = 1115444,
      .offset_limit = 1115512,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_181_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116576,
      .offset_end = 1116577,
      .offset_limit = 1116648,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_183_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 524288,
      .offset_end = 557056,
      .offset_limit = 557120,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_256_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_256_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_183_weights_quant_scale,
      .offset = buff_info_Conv2D_183_weights_quant_offset,
    },
    {
      .name = "Conv2D_189_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 557056,
      .offset_end = 589824,
      .offset_limit = 589888,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_256_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_189_weights_quant_scale,
      .offset = buff_info_Conv2D_189_weights_quant_offset,
    },
    {
      .name = "Dequantize_191_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115008,
      .offset_end = 1115012,
      .offset_limit = 1115080,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_191_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116144,
      .offset_end = 1116145,
      .offset_limit = 1116216,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_193_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115456,
      .offset_end = 1115460,
      .offset_limit = 1115528,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_193_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116592,
      .offset_end = 1116593,
      .offset_limit = 1116664,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_197_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115024,
      .offset_end = 1115028,
      .offset_limit = 1115096,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_197_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116160,
      .offset_end = 1116161,
      .offset_limit = 1116232,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_199_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115472,
      .offset_end = 1115476,
      .offset_limit = 1115544,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_199_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116608,
      .offset_end = 1116609,
      .offset_limit = 1116680,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_201_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 589824,
      .offset_end = 622592,
      .offset_limit = 622656,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_256_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_256_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_201_weights_quant_scale,
      .offset = buff_info_Conv2D_201_weights_quant_offset,
    },
    {
      .name = "Conv2D_207_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 622592,
      .offset_end = 655360,
      .offset_limit = 655424,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_256_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_207_weights_quant_scale,
      .offset = buff_info_Conv2D_207_weights_quant_offset,
    },
    {
      .name = "Dequantize_209_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115040,
      .offset_end = 1115044,
      .offset_limit = 1115112,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_209_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116176,
      .offset_end = 1116177,
      .offset_limit = 1116248,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_211_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115488,
      .offset_end = 1115492,
      .offset_limit = 1115560,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_211_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116624,
      .offset_end = 1116625,
      .offset_limit = 1116696,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_215_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115056,
      .offset_end = 1115060,
      .offset_limit = 1115128,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_215_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116192,
      .offset_end = 1116193,
      .offset_limit = 1116264,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_217_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115504,
      .offset_end = 1115508,
      .offset_limit = 1115576,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_217_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116640,
      .offset_end = 1116641,
      .offset_limit = 1116712,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_219_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 655360,
      .offset_end = 688128,
      .offset_limit = 688192,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_256_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_256_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_219_weights_quant_scale,
      .offset = buff_info_Conv2D_219_weights_quant_offset,
    },
    {
      .name = "Conv2D_225_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 0,
      .offset_end = 65536,
      .offset_limit = 65600,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_512_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_512_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_225_weights_quant_scale,
      .offset = buff_info_Conv2D_225_weights_quant_offset,
    },
    {
      .name = "Dequantize_227_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114800,
      .offset_end = 1114804,
      .offset_limit = 1114872,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_227_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115936,
      .offset_end = 1115937,
      .offset_limit = 1116008,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_229_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115216,
      .offset_end = 1115220,
      .offset_limit = 1115288,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_229_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116352,
      .offset_end = 1116353,
      .offset_limit = 1116424,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_233_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115232,
      .offset_end = 1115236,
      .offset_limit = 1115304,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_233_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116368,
      .offset_end = 1116369,
      .offset_limit = 1116440,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_235_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115600,
      .offset_end = 1115604,
      .offset_limit = 1115672,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_235_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116736,
      .offset_end = 1116737,
      .offset_limit = 1116808,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_237_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 65536,
      .offset_end = 131072,
      .offset_limit = 131136,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_512_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_512_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_237_weights_quant_scale,
      .offset = buff_info_Conv2D_237_weights_quant_offset,
    },
    {
      .name = "Conv2D_240_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 688128,
      .offset_end = 720896,
      .offset_limit = 720960,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_256_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_240_weights_quant_scale,
      .offset = buff_info_Conv2D_240_weights_quant_offset,
    },
    {
      .name = "Dequantize_242_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115520,
      .offset_end = 1115524,
      .offset_limit = 1115592,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_242_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116656,
      .offset_end = 1116657,
      .offset_limit = 1116728,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_244_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115632,
      .offset_end = 1115636,
      .offset_limit = 1115704,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_244_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116768,
      .offset_end = 1116769,
      .offset_limit = 1116840,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_248_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115536,
      .offset_end = 1115540,
      .offset_limit = 1115608,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_248_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116672,
      .offset_end = 1116673,
      .offset_limit = 1116744,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_250_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115648,
      .offset_end = 1115652,
      .offset_limit = 1115720,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_250_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116784,
      .offset_end = 1116785,
      .offset_limit = 1116856,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_252_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 720896,
      .offset_end = 753664,
      .offset_limit = 753728,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_256_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_256_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_252_weights_quant_scale,
      .offset = buff_info_Conv2D_252_weights_quant_offset,
    },
    {
      .name = "Conv2D_258_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 753664,
      .offset_end = 786432,
      .offset_limit = 786496,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_256_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_258_weights_quant_scale,
      .offset = buff_info_Conv2D_258_weights_quant_offset,
    },
    {
      .name = "Dequantize_260_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115552,
      .offset_end = 1115556,
      .offset_limit = 1115624,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_260_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116688,
      .offset_end = 1116689,
      .offset_limit = 1116760,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_262_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115664,
      .offset_end = 1115668,
      .offset_limit = 1115736,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_262_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116800,
      .offset_end = 1116801,
      .offset_limit = 1116872,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_266_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115568,
      .offset_end = 1115572,
      .offset_limit = 1115640,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_266_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116704,
      .offset_end = 1116705,
      .offset_limit = 1116776,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_268_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115680,
      .offset_end = 1115684,
      .offset_limit = 1115752,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_268_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116816,
      .offset_end = 1116817,
      .offset_limit = 1116888,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_270_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 786432,
      .offset_end = 819200,
      .offset_limit = 819264,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_256_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_256_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_270_weights_quant_scale,
      .offset = buff_info_Conv2D_270_weights_quant_offset,
    },
    {
      .name = "Conv2D_276_weights",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 131072,
      .offset_end = 196608,
      .offset_limit = 196672,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_512_128_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_512_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_276_weights_quant_scale,
      .offset = buff_info_Conv2D_276_weights_quant_offset,
    },
    {
      .name = "Dequantize_278_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115248,
      .offset_end = 1115252,
      .offset_limit = 1115320,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_278_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116384,
      .offset_end = 1116385,
      .offset_limit = 1116456,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_280_y_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115616,
      .offset_end = 1115620,
      .offset_limit = 1115688,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Quantize_280_y_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116752,
      .offset_end = 1116753,
      .offset_limit = 1116824,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_288_x_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115696,
      .offset_end = 1115700,
      .offset_limit = 1115768,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Dequantize_288_x_zero_point",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116832,
      .offset_end = 1116833,
      .offset_limit = 1116904,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "BatchNormalization_289_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1111984,
      .offset_end = 1112496,
      .offset_limit = 1112560,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_128,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_128,
    },
    {
      .name = "BatchNormalization_289_B",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1112496,
      .offset_end = 1113008,
      .offset_limit = 1113072,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_128,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 31,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_128,
    },
    {
      .name = "BatchNormalization_289_input_mean",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1113008,
      .offset_end = 1113520,
      .offset_limit = 1113584,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_128,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_128,
    },
    {
      .name = "BatchNormalization_289_input_var",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1113520,
      .offset_end = 1114032,
      .offset_limit = 1114096,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_128,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_128,
    },
    {
      .name = "Gemm_286_weights_transposed_3",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 196608,
      .offset_end = 262144,
      .offset_limit = 262208,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_128_512_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_512_1_1,
      .per_channel = 0,
      .scale = buff_info_Gemm_286_weights_transposed_3_quant_scale,
      .offset = buff_info_Gemm_286_weights_transposed_3_quant_offset,
    },
    {
      .name = "Conv2D_9_weights_inflated_454",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1075712,
      .offset_end = 1078016,
      .offset_limit = 1078080,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_64_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_64_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_9_weights_inflated_454_quant_scale,
      .offset = buff_info_Conv2D_9_weights_inflated_454_quant_offset,
    },
    {
      .name = "Conv2D_21_weights_inflated_456",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1049600,
      .offset_end = 1054208,
      .offset_limit = 1054272,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_128_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_21_weights_inflated_456_quant_scale,
      .offset = buff_info_Conv2D_21_weights_inflated_456_quant_offset,
    },
    {
      .name = "Conv2D_36_weights_inflated_458",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1054208,
      .offset_end = 1058816,
      .offset_limit = 1058880,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_128_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_36_weights_inflated_458_quant_scale,
      .offset = buff_info_Conv2D_36_weights_inflated_458_quant_offset,
    },
    {
      .name = "Conv2D_54_weights_inflated_460",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1058816,
      .offset_end = 1063424,
      .offset_limit = 1063488,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_128_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_54_weights_inflated_460_quant_scale,
      .offset = buff_info_Conv2D_54_weights_inflated_460_quant_offset,
    },
    {
      .name = "Conv2D_72_weights_inflated_462",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1063424,
      .offset_end = 1068032,
      .offset_limit = 1068096,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_128_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_72_weights_inflated_462_quant_scale,
      .offset = buff_info_Conv2D_72_weights_inflated_462_quant_offset,
    },
    {
      .name = "Conv2D_90_weights_inflated_464",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1068032,
      .offset_end = 1072640,
      .offset_limit = 1072704,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_128_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_128_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_90_weights_inflated_464_quant_scale,
      .offset = buff_info_Conv2D_90_weights_inflated_464_quant_offset,
    },
    {
      .name = "Conv2D_108_weights_inflated_466",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 854016,
      .offset_end = 863232,
      .offset_limit = 863296,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_256_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_108_weights_inflated_466_quant_scale,
      .offset = buff_info_Conv2D_108_weights_inflated_466_quant_offset,
    },
    {
      .name = "Conv2D_123_weights_inflated_468",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 863232,
      .offset_end = 872448,
      .offset_limit = 872512,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_256_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_123_weights_inflated_468_quant_scale,
      .offset = buff_info_Conv2D_123_weights_inflated_468_quant_offset,
    },
    {
      .name = "Conv2D_141_weights_inflated_470",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 872448,
      .offset_end = 881664,
      .offset_limit = 881728,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_256_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_141_weights_inflated_470_quant_scale,
      .offset = buff_info_Conv2D_141_weights_inflated_470_quant_offset,
    },
    {
      .name = "Conv2D_159_weights_inflated_472",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 881664,
      .offset_end = 890880,
      .offset_limit = 890944,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_256_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_159_weights_inflated_472_quant_scale,
      .offset = buff_info_Conv2D_159_weights_inflated_472_quant_offset,
    },
    {
      .name = "Conv2D_177_weights_inflated_474",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 890880,
      .offset_end = 900096,
      .offset_limit = 900160,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_256_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_177_weights_inflated_474_quant_scale,
      .offset = buff_info_Conv2D_177_weights_inflated_474_quant_offset,
    },
    {
      .name = "Conv2D_195_weights_inflated_476",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 900096,
      .offset_end = 909312,
      .offset_limit = 909376,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_256_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_195_weights_inflated_476_quant_scale,
      .offset = buff_info_Conv2D_195_weights_inflated_476_quant_offset,
    },
    {
      .name = "Conv2D_213_weights_inflated_478",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 909312,
      .offset_end = 918528,
      .offset_limit = 918592,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_256_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_213_weights_inflated_478_quant_scale,
      .offset = buff_info_Conv2D_213_weights_inflated_478_quant_offset,
    },
    {
      .name = "Conv2D_231_weights_inflated_480",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 819200,
      .offset_end = 837632,
      .offset_limit = 837696,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_512_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_512_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_231_weights_inflated_480_quant_scale,
      .offset = buff_info_Conv2D_231_weights_inflated_480_quant_offset,
    },
    {
      .name = "Conv2D_246_weights_inflated_482",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 918528,
      .offset_end = 927744,
      .offset_limit = 927808,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_256_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_246_weights_inflated_482_quant_scale,
      .offset = buff_info_Conv2D_246_weights_inflated_482_quant_offset,
    },
    {
      .name = "Conv2D_264_weights_inflated_484",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 927744,
      .offset_end = 936960,
      .offset_limit = 937024,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 4,
      .mem_shape = buff_info__mem_shape_L_256_4_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_256_4_3_3,
      .per_channel = 0,
      .scale = buff_info_Conv2D_264_weights_inflated_484_quant_scale,
      .offset = buff_info_Conv2D_264_weights_inflated_484_quant_offset,
    },
    {
      .name = "Conv2D_282_weights_submask_0_0_0_0_512_1_3_6_486",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 936960,
      .offset_end = 946176,
      .offset_limit = 946240,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_512_1_3_6,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_512_1_3_6,
      .per_channel = 0,
      .scale = buff_info_Conv2D_282_weights_submask_0_0_0_0_512_1_3_6_486_quant_scale,
      .offset = buff_info_Conv2D_282_weights_submask_0_0_0_0_512_1_3_6_486_quant_offset,
    },
    {
      .name = "Conv2D_282_weights_submask_0_0_3_0_512_1_3_6_487",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 946176,
      .offset_end = 955392,
      .offset_limit = 955456,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_512_1_3_6,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_512_1_3_6,
      .per_channel = 0,
      .scale = buff_info_Conv2D_282_weights_submask_0_0_3_0_512_1_3_6_487_quant_scale,
      .offset = buff_info_Conv2D_282_weights_submask_0_0_3_0_512_1_3_6_487_quant_offset,
    },
    {
      .name = "Conv2D_282_weights_submask_0_0_0_6_512_1_3_1_488",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1037312,
      .offset_end = 1043456,
      .offset_limit = 1043520,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_512_1_3_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_512_1_3_1,
    },
    {
      .name = "Conv2D_282_weights_submask_0_0_3_6_512_1_3_1_489",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1043456,
      .offset_end = 1049600,
      .offset_limit = 1049664,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_512_1_3_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_512_1_3_1,
    },
    {
      .name = "Conv2D_282_weights_submask_0_0_6_0_512_1_1_6_490",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1072640,
      .offset_end = 1075712,
      .offset_limit = 1075776,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_512_1_1_6,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_512_1_1_6,
      .per_channel = 0,
      .scale = buff_info_Conv2D_282_weights_submask_0_0_6_0_512_1_1_6_490_quant_scale,
      .offset = buff_info_Conv2D_282_weights_submask_0_0_6_0_512_1_1_6_490_quant_offset,
    },
    {
      .name = "Conv2D_282_weights_submask_0_0_6_6_512_1_1_1_491",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1084208,
      .offset_end = 1086256,
      .offset_limit = 1086320,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_512_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_512_1_1_1,
    },
    {
      .name = "PReLU_6_1196__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114032,
      .offset_end = 1114292,
      .offset_limit = 1114360,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 65,
      .mem_shape = buff_info__mem_shape_F_1_65_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_65_1_1,
    },
    {
      .name = "PReLU_12_1197__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1114304,
      .offset_end = 1114564,
      .offset_limit = 1114632,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 65,
      .mem_shape = buff_info__mem_shape_F_1_65_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_65_1_1,
    },
    {
      .name = "PReLU_18_1198__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1106704,
      .offset_end = 1107220,
      .offset_limit = 1107288,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 129,
      .mem_shape = buff_info__mem_shape_F_1_129_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_129_1_1,
    },
    {
      .name = "PReLU_24_1199__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1107232,
      .offset_end = 1107748,
      .offset_limit = 1107816,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 129,
      .mem_shape = buff_info__mem_shape_F_1_129_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_129_1_1,
    },
    {
      .name = "PReLU_33_1200__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1107760,
      .offset_end = 1108276,
      .offset_limit = 1108344,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 129,
      .mem_shape = buff_info__mem_shape_F_1_129_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_129_1_1,
    },
    {
      .name = "PReLU_39_1201__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1108288,
      .offset_end = 1108804,
      .offset_limit = 1108872,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 129,
      .mem_shape = buff_info__mem_shape_F_1_129_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_129_1_1,
    },
    {
      .name = "PReLU_51_1202__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1108816,
      .offset_end = 1109332,
      .offset_limit = 1109400,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 129,
      .mem_shape = buff_info__mem_shape_F_1_129_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_129_1_1,
    },
    {
      .name = "PReLU_57_1203__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1109344,
      .offset_end = 1109860,
      .offset_limit = 1109928,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 129,
      .mem_shape = buff_info__mem_shape_F_1_129_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_129_1_1,
    },
    {
      .name = "PReLU_69_1204__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1109872,
      .offset_end = 1110388,
      .offset_limit = 1110456,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 129,
      .mem_shape = buff_info__mem_shape_F_1_129_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_129_1_1,
    },
    {
      .name = "PReLU_75_1205__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1110400,
      .offset_end = 1110916,
      .offset_limit = 1110984,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 129,
      .mem_shape = buff_info__mem_shape_F_1_129_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_129_1_1,
    },
    {
      .name = "PReLU_87_1206__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1110928,
      .offset_end = 1111444,
      .offset_limit = 1111512,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 129,
      .mem_shape = buff_info__mem_shape_F_1_129_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_129_1_1,
    },
    {
      .name = "PReLU_93_1207__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1111456,
      .offset_end = 1111972,
      .offset_limit = 1112040,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 129,
      .mem_shape = buff_info__mem_shape_F_1_129_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_129_1_1,
    },
    {
      .name = "PReLU_105_1208__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1087984,
      .offset_end = 1089012,
      .offset_limit = 1089080,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_111_1209__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1089024,
      .offset_end = 1090052,
      .offset_limit = 1090120,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_120_1210__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1090064,
      .offset_end = 1091092,
      .offset_limit = 1091160,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_126_1211__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1091104,
      .offset_end = 1092132,
      .offset_limit = 1092200,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_138_1212__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1092144,
      .offset_end = 1093172,
      .offset_limit = 1093240,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_144_1213__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1093184,
      .offset_end = 1094212,
      .offset_limit = 1094280,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_156_1214__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1094224,
      .offset_end = 1095252,
      .offset_limit = 1095320,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_162_1215__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1095264,
      .offset_end = 1096292,
      .offset_limit = 1096360,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_174_1216__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1096304,
      .offset_end = 1097332,
      .offset_limit = 1097400,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_180_1217__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1097344,
      .offset_end = 1098372,
      .offset_limit = 1098440,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_192_1218__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1098384,
      .offset_end = 1099412,
      .offset_limit = 1099480,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_198_1219__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1099424,
      .offset_end = 1100452,
      .offset_limit = 1100520,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_210_1220__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1100464,
      .offset_end = 1101492,
      .offset_limit = 1101560,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_216_1221__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1101504,
      .offset_end = 1102532,
      .offset_limit = 1102600,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_228_1222__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1078016,
      .offset_end = 1080068,
      .offset_limit = 1080136,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 513,
      .mem_shape = buff_info__mem_shape_F_1_513_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_513_1_1,
    },
    {
      .name = "PReLU_234_1223__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1080080,
      .offset_end = 1082132,
      .offset_limit = 1082200,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 513,
      .mem_shape = buff_info__mem_shape_F_1_513_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_513_1_1,
    },
    {
      .name = "PReLU_243_1224__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1102544,
      .offset_end = 1103572,
      .offset_limit = 1103640,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_249_1225__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1103584,
      .offset_end = 1104612,
      .offset_limit = 1104680,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_261_1226__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1104624,
      .offset_end = 1105652,
      .offset_limit = 1105720,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_267_1227__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1105664,
      .offset_end = 1106692,
      .offset_limit = 1106760,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 257,
      .mem_shape = buff_info__mem_shape_F_1_257_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_257_1_1,
    },
    {
      .name = "PReLU_279_1228__slopes_",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1082144,
      .offset_end = 1084196,
      .offset_limit = 1084264,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 513,
      .mem_shape = buff_info__mem_shape_F_1_513_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_513_1_1,
    },
    {
      .name = "Conv2D_282_suboff_435_1229_atonn_internal_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115296,
      .offset_end = 1115300,
      .offset_limit = 1115368,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_282_suboff_435_1229_atonn_internal_offset",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116432,
      .offset_end = 1116433,
      .offset_limit = 1116504,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_282_suboff_435_1231_atonn_internal_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115280,
      .offset_end = 1115284,
      .offset_limit = 1115352,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_282_suboff_435_1231_atonn_internal_offset",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116416,
      .offset_end = 1116417,
      .offset_limit = 1116488,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_282_suboff_435_1233_atonn_internal_scale",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1115264,
      .offset_end = 1115268,
      .offset_limit = 1115336,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
    {
      .name = "Conv2D_282_suboff_435_1233_atonn_internal_offset",
      .addr_base = {(unsigned char *)(0x72000000UL) /* Equivalent hex address = 0x72000000UL */},
      .offset_start = 1116400,
      .offset_end = 1116401,
      .offset_limit = 1116472,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1,
      .mem_ndims = 1,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1,
    },
#endif // LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
    {
      .name = NULL,
    }
  };

  return buff_info;
}

const LL_Buffer_InfoTypeDef *LL_ATON_Output_Buffers_Info_face_recognition(void)
{
  static const uint32_t buff_info__shape_1_128[] = { 1, 1, 128, 1 };
  static const uint32_t buff_info__mem_shape_U_1_128[] = { 1, 128 };
  static const LL_Buffer_InfoTypeDef buff_info[] = {
    {
      .name = "BatchNormalization_289_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 512,
      .offset_limit = 576,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 164,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1_128,
      .mem_ndims = 2,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128,
    },
    {
      .name = NULL,
    }
  };

  return buff_info;
}

const LL_Buffer_InfoTypeDef *LL_ATON_Internal_Buffers_Info_face_recognition(void)
{
  static const uint32_t buff_info__shape_1_3_112_112[] = { 1, 112, 112, 3 };
  static const uint32_t buff_info__mem_shape_L_1_3_112_112[] = { 1, 112, 112, 3 };
  static const float buff_info_Quantize_1_out_0_quant_scale[] = { 0.00784313771873713 };
  static const int16_t buff_info_Quantize_1_out_0_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_1_64_56_56[] = { 1, 56, 56, 64 };
  static const uint32_t buff_info__mem_shape_L_1_64_56_56[] = { 1, 56, 56, 64 };
  static const float buff_info_Conv2D_3_off_bias_out_10_quant_scale[] = { 0.0134842870756984 };
  static const int16_t buff_info_Conv2D_3_off_bias_out_10_quant_offset[] = { -11 };
  static const float buff_info_Quantize_7_out_0_quant_scale[] = { 0.0107148718088865 };
  static const int16_t buff_info_Quantize_7_out_0_quant_offset[] = { -46 };
  static const float buff_info_Conv2D_9_off_bias_out_19_quant_scale[] = { 0.0271160919219255 };
  static const int16_t buff_info_Conv2D_9_off_bias_out_19_quant_offset[] = { 9 };
  static const float buff_info_Quantize_13_out_0_quant_scale[] = { 0.0168012846261263 };
  static const int16_t buff_info_Quantize_13_out_0_quant_offset[] = { -63 };
  static const uint32_t buff_info__shape_1_128_56_56[] = { 1, 56, 56, 128 };
  static const uint32_t buff_info__mem_shape_L_1_128_56_56[] = { 1, 56, 56, 128 };
  static const float buff_info_Conv2D_15_off_bias_out_28_quant_scale[] = { 0.0261620786041021 };
  static const int16_t buff_info_Conv2D_15_off_bias_out_28_quant_offset[] = { 17 };
  static const float buff_info_Quantize_19_out_0_quant_scale[] = { 0.0137048671022058 };
  static const int16_t buff_info_Quantize_19_out_0_quant_offset[] = { -83 };
  static const uint32_t buff_info__shape_1_128_28_28[] = { 1, 28, 28, 128 };
  static const uint32_t buff_info__mem_shape_L_1_128_28_28[] = { 1, 28, 28, 128 };
  static const float buff_info_Conv2D_21_off_bias_out_37_quant_scale[] = { 0.0228193327784538 };
  static const int16_t buff_info_Conv2D_21_off_bias_out_37_quant_offset[] = { -5 };
  static const float buff_info_Quantize_25_out_0_quant_scale[] = { 0.015931136906147 };
  static const int16_t buff_info_Quantize_25_out_0_quant_offset[] = { -62 };
  static const uint32_t buff_info__shape_1_64_28_28[] = { 1, 28, 28, 64 };
  static const uint32_t buff_info__mem_shape_M16_1_64_28_28[] = { 1, 4, 28, 28, 16 };
  static const float buff_info_Conv2D_27_off_bias_out_46_quant_scale[] = { 0.0166975948959589 };
  static const int16_t buff_info_Conv2D_27_off_bias_out_46_quant_offset[] = { 8 };
  static const float buff_info_Conv2D_30_off_bias_out_55_quant_scale[] = { 0.0067789638414979 };
  static const int16_t buff_info_Conv2D_30_off_bias_out_55_quant_offset[] = { 16 };
  static const float buff_info_Quantize_34_out_0_quant_scale[] = { 0.00407668296247721 };
  static const int16_t buff_info_Quantize_34_out_0_quant_offset[] = { -57 };
  static const float buff_info_Conv2D_36_off_bias_out_64_quant_scale[] = { 0.0122979590669274 };
  static const int16_t buff_info_Conv2D_36_off_bias_out_64_quant_offset[] = { -13 };
  static const float buff_info_Quantize_40_out_0_quant_scale[] = { 0.0078753512352705 };
  static const int16_t buff_info_Quantize_40_out_0_quant_offset[] = { -92 };
  static const float buff_info_Add_45_out_0_quant_scale[] = { 0.0182412620633841 };
  static const int16_t buff_info_Add_45_out_0_quant_offset[] = { -7 };
  static const float buff_info_Conv2D_48_off_bias_out_82_quant_scale[] = { 0.00744301592931151 };
  static const int16_t buff_info_Conv2D_48_off_bias_out_82_quant_offset[] = { -5 };
  static const float buff_info_Quantize_52_out_0_quant_scale[] = { 0.00460905954241753 };
  static const int16_t buff_info_Quantize_52_out_0_quant_offset[] = { -87 };
  static const float buff_info_Conv2D_54_off_bias_out_91_quant_scale[] = { 0.0178707297891378 };
  static const int16_t buff_info_Conv2D_54_off_bias_out_91_quant_offset[] = { 20 };
  static const float buff_info_Quantize_58_out_0_quant_scale[] = { 0.00884974375367165 };
  static const int16_t buff_info_Quantize_58_out_0_quant_offset[] = { -89 };
  static const float buff_info_Add_63_out_0_quant_scale[] = { 0.0179424677044153 };
  static const int16_t buff_info_Add_63_out_0_quant_offset[] = { -6 };
  static const float buff_info_Conv2D_66_off_bias_out_109_quant_scale[] = { 0.00648566102609038 };
  static const int16_t buff_info_Conv2D_66_off_bias_out_109_quant_offset[] = { 23 };
  static const float buff_info_Quantize_70_out_0_quant_scale[] = { 0.00343898916617036 };
  static const int16_t buff_info_Quantize_70_out_0_quant_offset[] = { -69 };
  static const float buff_info_Conv2D_72_off_bias_out_118_quant_scale[] = { 0.0203138515353203 };
  static const int16_t buff_info_Conv2D_72_off_bias_out_118_quant_offset[] = { 21 };
  static const float buff_info_Quantize_76_out_0_quant_scale[] = { 0.00907684210687876 };
  static const int16_t buff_info_Quantize_76_out_0_quant_offset[] = { -110 };
  static const float buff_info_Add_81_out_0_quant_scale[] = { 0.021410059183836 };
  static const int16_t buff_info_Add_81_out_0_quant_offset[] = { 6 };
  static const float buff_info_Conv2D_84_off_bias_out_136_quant_scale[] = { 0.0074297315441072 };
  static const int16_t buff_info_Conv2D_84_off_bias_out_136_quant_offset[] = { 3 };
  static const float buff_info_Quantize_88_out_0_quant_scale[] = { 0.00442239316180348 };
  static const int16_t buff_info_Quantize_88_out_0_quant_offset[] = { -81 };
  static const float buff_info_Conv2D_90_off_bias_out_145_quant_scale[] = { 0.0174313187599182 };
  static const int16_t buff_info_Conv2D_90_off_bias_out_145_quant_offset[] = { -10 };
  static const float buff_info_Quantize_94_out_0_quant_scale[] = { 0.0107026668265462 };
  static const int16_t buff_info_Quantize_94_out_0_quant_offset[] = { -96 };
  static const float buff_info_Add_99_out_0_quant_scale[] = { 0.0341380089521408 };
  static const int16_t buff_info_Add_99_out_0_quant_offset[] = { 25 };
  static const uint32_t buff_info__shape_1_256_28_28[] = { 1, 28, 28, 256 };
  static const uint32_t buff_info__mem_shape_L_1_256_28_28[] = { 1, 28, 28, 256 };
  static const float buff_info_Conv2D_102_off_bias_out_163_quant_scale[] = { 0.00922307744622231 };
  static const int16_t buff_info_Conv2D_102_off_bias_out_163_quant_offset[] = { 27 };
  static const float buff_info_Quantize_106_out_0_quant_scale[] = { 0.00432290649041533 };
  static const int16_t buff_info_Quantize_106_out_0_quant_offset[] = { -85 };
  static const uint32_t buff_info__shape_1_256_14_14[] = { 1, 14, 14, 256 };
  static const uint32_t buff_info__mem_shape_L_1_256_14_14[] = { 1, 14, 14, 256 };
  static const float buff_info_Conv2D_108_off_bias_out_172_quant_scale[] = { 0.0146649330854416 };
  static const int16_t buff_info_Conv2D_108_off_bias_out_172_quant_offset[] = { 28 };
  static const float buff_info_Quantize_112_out_0_quant_scale[] = { 0.00869098491966724 };
  static const int16_t buff_info_Quantize_112_out_0_quant_offset[] = { -40 };
  static const uint32_t buff_info__shape_1_128_14_14[] = { 1, 14, 14, 128 };
  static const uint32_t buff_info__mem_shape_M16_1_128_14_14[] = { 1, 8, 14, 14, 16 };
  static const float buff_info_Conv2D_114_off_bias_out_181_quant_scale[] = { 0.0106604732573032 };
  static const int16_t buff_info_Conv2D_114_off_bias_out_181_quant_offset[] = { -10 };
  static const uint32_t buff_info__mem_shape_M16_1_256_14_14[] = { 1, 16, 14, 14, 16 };
  static const float buff_info_Conv2D_117_off_bias_out_190_quant_scale[] = { 0.00436006253585219 };
  static const int16_t buff_info_Conv2D_117_off_bias_out_190_quant_offset[] = { 10 };
  static const float buff_info_Quantize_121_out_0_quant_scale[] = { 0.00249716523103416 };
  static const int16_t buff_info_Quantize_121_out_0_quant_offset[] = { -78 };
  static const float buff_info_Conv2D_123_off_bias_out_199_quant_scale[] = { 0.00746955489739776 };
  static const int16_t buff_info_Conv2D_123_off_bias_out_199_quant_offset[] = { 15 };
  static const float buff_info_Quantize_127_out_0_quant_scale[] = { 0.00362139893695712 };
  static const int16_t buff_info_Quantize_127_out_0_quant_offset[] = { -104 };
  static const float buff_info_Add_132_out_0_quant_scale[] = { 0.0108809368684888 };
  static const int16_t buff_info_Add_132_out_0_quant_offset[] = { -13 };
  static const float buff_info_Conv2D_135_off_bias_out_217_quant_scale[] = { 0.00429799454286695 };
  static const int16_t buff_info_Conv2D_135_off_bias_out_217_quant_offset[] = { 25 };
  static const float buff_info_Quantize_139_out_0_quant_scale[] = { 0.00214668968692422 };
  static const int16_t buff_info_Quantize_139_out_0_quant_offset[] = { -78 };
  static const float buff_info_Conv2D_141_off_bias_out_226_quant_scale[] = { 0.0102742249146104 };
  static const int16_t buff_info_Conv2D_141_off_bias_out_226_quant_offset[] = { 34 };
  static const float buff_info_Quantize_145_out_0_quant_scale[] = { 0.0040876716375351 };
  static const int16_t buff_info_Quantize_145_out_0_quant_offset[] = { -107 };
  static const float buff_info_Add_150_out_0_quant_scale[] = { 0.0110058896243572 };
  static const int16_t buff_info_Add_150_out_0_quant_offset[] = { -13 };
  static const float buff_info_Conv2D_153_off_bias_out_244_quant_scale[] = { 0.00366343837231398 };
  static const int16_t buff_info_Conv2D_153_off_bias_out_244_quant_offset[] = { 18 };
  static const float buff_info_Quantize_157_out_0_quant_scale[] = { 0.00197141896933317 };
  static const int16_t buff_info_Quantize_157_out_0_quant_offset[] = { -75 };
  static const float buff_info_Conv2D_159_off_bias_out_253_quant_scale[] = { 0.00807404797524214 };
  static const int16_t buff_info_Conv2D_159_off_bias_out_253_quant_offset[] = { 22 };
  static const float buff_info_Quantize_163_out_0_quant_scale[] = { 0.00356822740286589 };
  static const int16_t buff_info_Quantize_163_out_0_quant_offset[] = { -110 };
  static const float buff_info_Add_168_out_0_quant_scale[] = { 0.0108656836673617 };
  static const int16_t buff_info_Add_168_out_0_quant_offset[] = { -9 };
  static const float buff_info_Conv2D_171_off_bias_out_271_quant_scale[] = { 0.00426460197195411 };
  static const int16_t buff_info_Conv2D_171_off_bias_out_271_quant_offset[] = { 1 };
  static const float buff_info_Quantize_175_out_0_quant_scale[] = { 0.00242237490601838 };
  static const int16_t buff_info_Quantize_175_out_0_quant_offset[] = { -95 };
  static const float buff_info_Conv2D_177_off_bias_out_280_quant_scale[] = { 0.0117450701072812 };
  static const int16_t buff_info_Conv2D_177_off_bias_out_280_quant_offset[] = { 25 };
  static const float buff_info_Quantize_181_out_0_quant_scale[] = { 0.00555905839428306 };
  static const int16_t buff_info_Quantize_181_out_0_quant_offset[] = { -88 };
  static const float buff_info_Add_186_out_0_quant_scale[] = { 0.012066007591784 };
  static const int16_t buff_info_Add_186_out_0_quant_offset[] = { 3 };
  static const float buff_info_Conv2D_189_off_bias_out_298_quant_scale[] = { 0.00386737799271941 };
  static const int16_t buff_info_Conv2D_189_off_bias_out_298_quant_offset[] = { 6 };
  static const float buff_info_Quantize_193_out_0_quant_scale[] = { 0.00241226213984191 };
  static const int16_t buff_info_Quantize_193_out_0_quant_offset[] = { -67 };
  static const float buff_info_Conv2D_195_off_bias_out_307_quant_scale[] = { 0.00981520861387253 };
  static const int16_t buff_info_Conv2D_195_off_bias_out_307_quant_offset[] = { 3 };
  static const float buff_info_Quantize_199_out_0_quant_scale[] = { 0.00577217014506459 };
  static const int16_t buff_info_Quantize_199_out_0_quant_offset[] = { -83 };
  static const float buff_info_Add_204_out_0_quant_scale[] = { 0.0149685861542821 };
  static const int16_t buff_info_Add_204_out_0_quant_offset[] = { 10 };
  static const float buff_info_Conv2D_207_off_bias_out_325_quant_scale[] = { 0.00412362068891525 };
  static const int16_t buff_info_Conv2D_207_off_bias_out_325_quant_offset[] = { 4 };
  static const float buff_info_Quantize_211_out_0_quant_scale[] = { 0.00244737672619522 };
  static const int16_t buff_info_Quantize_211_out_0_quant_offset[] = { -80 };
  static const float buff_info_Conv2D_213_off_bias_out_334_quant_scale[] = { 0.0116236628964543 };
  static const int16_t buff_info_Conv2D_213_off_bias_out_334_quant_offset[] = { 5 };
  static const float buff_info_Quantize_217_out_0_quant_scale[] = { 0.00659493776038289 };
  static const int16_t buff_info_Quantize_217_out_0_quant_offset[] = { -89 };
  static const float buff_info_Add_222_out_0_quant_scale[] = { 0.0251358132809401 };
  static const int16_t buff_info_Add_222_out_0_quant_offset[] = { 10 };
  static const uint32_t buff_info__shape_1_512_14_14[] = { 1, 14, 14, 512 };
  static const uint32_t buff_info__mem_shape_M16_1_512_14_14[] = { 1, 32, 14, 14, 16 };
  static const uint32_t buff_info__mem_shape_L_1_512_14_14[] = { 1, 14, 14, 512 };
  static const float buff_info_Conv2D_225_off_bias_out_352_quant_scale[] = { 0.0050009679980576 };
  static const int16_t buff_info_Conv2D_225_off_bias_out_352_quant_offset[] = { 9 };
  static const float buff_info_Quantize_229_out_0_quant_scale[] = { 0.00274793175049126 };
  static const int16_t buff_info_Quantize_229_out_0_quant_offset[] = { -89 };
  static const uint32_t buff_info__shape_1_512_7_7[] = { 1, 7, 7, 512 };
  static const uint32_t buff_info__mem_shape_L_1_512_7_7[] = { 1, 7, 7, 512 };
  static const float buff_info_Conv2D_231_off_bias_out_361_quant_scale[] = { 0.0112832877784967 };
  static const int16_t buff_info_Conv2D_231_off_bias_out_361_quant_offset[] = { 15 };
  static const float buff_info_Quantize_235_out_0_quant_scale[] = { 0.00687723327428102 };
  static const int16_t buff_info_Quantize_235_out_0_quant_offset[] = { -56 };
  static const uint32_t buff_info__shape_1_128_7_7[] = { 1, 7, 7, 128 };
  static const uint32_t buff_info__mem_shape_M16_1_128_7_7[] = { 1, 8, 7, 7, 16 };
  static const float buff_info_Conv2D_237_off_bias_out_370_quant_scale[] = { 0.00730226282030344 };
  static const int16_t buff_info_Conv2D_237_off_bias_out_370_quant_offset[] = { -4 };
  static const uint32_t buff_info__shape_1_256_7_7[] = { 1, 7, 7, 256 };
  static const uint32_t buff_info__mem_shape_M16_1_256_7_7[] = { 1, 16, 7, 7, 16 };
  static const uint32_t buff_info__mem_shape_L_1_256_7_7[] = { 1, 7, 7, 256 };
  static const float buff_info_Conv2D_240_off_bias_out_379_quant_scale[] = { 0.00312880729325116 };
  static const int16_t buff_info_Conv2D_240_off_bias_out_379_quant_offset[] = { -9 };
  static const float buff_info_Quantize_244_out_0_quant_scale[] = { 0.00195949943736196 };
  static const int16_t buff_info_Quantize_244_out_0_quant_offset[] = { -90 };
  static const float buff_info_Conv2D_246_off_bias_out_388_quant_scale[] = { 0.00694649899378419 };
  static const int16_t buff_info_Conv2D_246_off_bias_out_388_quant_offset[] = { 28 };
  static const float buff_info_Quantize_250_out_0_quant_scale[] = { 0.00309472274966538 };
  static const int16_t buff_info_Quantize_250_out_0_quant_offset[] = { -96 };
  static const float buff_info_Add_255_out_0_quant_scale[] = { 0.00778867024928331 };
  static const int16_t buff_info_Add_255_out_0_quant_offset[] = { -3 };
  static const float buff_info_Conv2D_258_off_bias_out_406_quant_scale[] = { 0.00346772186458111 };
  static const int16_t buff_info_Conv2D_258_off_bias_out_406_quant_offset[] = { 6 };
  static const float buff_info_Quantize_262_out_0_quant_scale[] = { 0.00224185385741293 };
  static const int16_t buff_info_Quantize_262_out_0_quant_offset[] = { -61 };
  static const float buff_info_Conv2D_264_off_bias_out_415_quant_scale[] = { 0.0123765589669347 };
  static const int16_t buff_info_Conv2D_264_off_bias_out_415_quant_offset[] = { 34 };
  static const float buff_info_Quantize_268_out_0_quant_scale[] = { 0.00507969548925757 };
  static const int16_t buff_info_Quantize_268_out_0_quant_offset[] = { -101 };
  static const float buff_info_Add_273_out_0_quant_scale[] = { 0.0104150865226984 };
  static const int16_t buff_info_Add_273_out_0_quant_offset[] = { -23 };
  static const uint32_t buff_info__mem_shape_M16_1_512_7_7[] = { 1, 32, 7, 7, 16 };
  static const float buff_info_Conv2D_276_off_bias_out_433_quant_scale[] = { 0.00573027180507779 };
  static const int16_t buff_info_Conv2D_276_off_bias_out_433_quant_offset[] = { 23 };
  static const float buff_info_Quantize_280_out_0_quant_scale[] = { 0.00287175783887506 };
  static const int16_t buff_info_Quantize_280_out_0_quant_offset[] = { -104 };
  static const uint32_t buff_info__shape_1_512_1_1[] = { 1, 1, 1, 512 };
  static const uint32_t buff_info__mem_shape_F_1_512_1_1[] = { 1, 512, 1, 1 };
  static const float buff_info_Conv2D_282_zero_off_out_436_quant_scale[] = { 0.00287175783887506 };
  static const int16_t buff_info_Conv2D_282_zero_off_out_436_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_282_off_bias_out_442_quant_scale[] = { 0.00487982528284192 };
  static const int16_t buff_info_Conv2D_282_off_bias_out_442_quant_offset[] = { 6 };
  static const uint32_t buff_info__shape_1_128_1_1[] = { 1, 1, 1, 128 };
  static const uint32_t buff_info__mem_shape_F_1_128_1_1[] = { 1, 128, 1, 1 };
  static const float buff_info_Gemm_286_conv_4_off_bias_out_451_quant_scale[] = { 0.00282602966763079 };
  static const int16_t buff_info_Gemm_286_conv_4_off_bias_out_451_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_1_128[] = { 1, 1, 128, 1 };
  static const uint32_t buff_info__mem_shape_U_1_128[] = { 1, 128 };
  static const float buff_info_Gemm_286_out_0_quant_scale[] = { 0.00282602966763079 };
  static const int16_t buff_info_Gemm_286_out_0_quant_offset[] = { 0 };
  static const LL_Buffer_InfoTypeDef buff_info[] = {
    {
      .name = "Input_0_out_0_inserted_out1093",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 150528,
      .offset_end = 301056,
      .offset_limit = 301120,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 1,
      .batch = 3,
      .mem_shape = buff_info__mem_shape_L_1_3_112_112,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_3_112_112,
    },
    {
      .name = "Quantize_1_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 301056,
      .offset_end = 338688,
      .offset_limit = 338752,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 2,
      .batch = 3,
      .mem_shape = buff_info__mem_shape_L_1_3_112_112,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_3_112_112,
      .per_channel = 0,
      .scale = buff_info_Quantize_1_out_0_quant_scale,
      .offset = buff_info_Quantize_1_out_0_quant_offset,
    },
    {
      .name = "Conv2D_3_off_bias_out_10",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 3,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_L_1_64_56_56,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_56_56,
      .per_channel = 0,
      .scale = buff_info_Conv2D_3_off_bias_out_10_quant_scale,
      .offset = buff_info_Conv2D_3_off_bias_out_10_quant_offset,
    },
    {
      .name = "Dequantize_5_out_0",
      .addr_base = {(unsigned char *)(0x34100000UL) /* Equivalent hex address = 0x34100000UL */},
      .offset_start = 0,
      .offset_end = 802816,
      .offset_limit = 802880,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 4,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_L_1_64_56_56,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_64_56_56,
    },
    {
      .name = "PReLU_6_out_0",
      .addr_base = {(unsigned char *)(0x34100000UL) /* Equivalent hex address = 0x34100000UL */},
      .offset_start = 802816,
      .offset_end = 1605632,
      .offset_limit = 1605696,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 5,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_L_1_64_56_56,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_64_56_56,
    },
    {
      .name = "Quantize_7_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 6,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_L_1_64_56_56,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_56_56,
      .per_channel = 0,
      .scale = buff_info_Quantize_7_out_0_quant_scale,
      .offset = buff_info_Quantize_7_out_0_quant_offset,
    },
    {
      .name = "Conv2D_9_off_bias_out_19",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 7,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_L_1_64_56_56,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_56_56,
      .per_channel = 0,
      .scale = buff_info_Conv2D_9_off_bias_out_19_quant_scale,
      .offset = buff_info_Conv2D_9_off_bias_out_19_quant_offset,
    },
    {
      .name = "Dequantize_11_out_0",
      .addr_base = {(unsigned char *)(0x34100000UL) /* Equivalent hex address = 0x34100000UL */},
      .offset_start = 0,
      .offset_end = 802816,
      .offset_limit = 802880,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 8,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_L_1_64_56_56,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_64_56_56,
    },
    {
      .name = "PReLU_12_out_0",
      .addr_base = {(unsigned char *)(0x34100000UL) /* Equivalent hex address = 0x34100000UL */},
      .offset_start = 1708032,
      .offset_end = 2510848,
      .offset_limit = 2510912,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 9,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_L_1_64_56_56,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_64_56_56,
    },
    {
      .name = "Quantize_13_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 10,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_L_1_64_56_56,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_56_56,
      .per_channel = 0,
      .scale = buff_info_Quantize_13_out_0_quant_scale,
      .offset = buff_info_Quantize_13_out_0_quant_offset,
    },
    {
      .name = "Conv2D_15_off_bias_out_28",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 11,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_56_56,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_56_56,
      .per_channel = 0,
      .scale = buff_info_Conv2D_15_off_bias_out_28_quant_scale,
      .offset = buff_info_Conv2D_15_off_bias_out_28_quant_offset,
    },
    {
      .name = "Dequantize_17_out_0",
      .addr_base = {(unsigned char *)(0x34100000UL) /* Equivalent hex address = 0x34100000UL */},
      .offset_start = 0,
      .offset_end = 1605632,
      .offset_limit = 1605696,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 12,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_56_56,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_56_56,
    },
    {
      .name = "PReLU_18_out_0",
      .addr_base = {(unsigned char *)(0x90000000UL) /* Equivalent hex address = 0x90000000UL */},
      .offset_start = 0,
      .offset_end = 1605632,
      .offset_limit = 1605696,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 13,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_56_56,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_56_56,
    },
    {
      .name = "Quantize_19_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 14,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_56_56,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_56_56,
      .per_channel = 0,
      .scale = buff_info_Quantize_19_out_0_quant_scale,
      .offset = buff_info_Quantize_19_out_0_quant_offset,
    },
    {
      .name = "Conv2D_21_off_bias_out_37",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 15,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Conv2D_21_off_bias_out_37_quant_scale,
      .offset = buff_info_Conv2D_21_off_bias_out_37_quant_offset,
    },
    {
      .name = "Dequantize_23_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 16,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "PReLU_24_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 17,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "Quantize_25_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 18,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Quantize_25_out_0_quant_scale,
      .offset = buff_info_Quantize_25_out_0_quant_offset,
    },
    {
      .name = "Conv2D_27_out_0_cp_in_4_cp_in_5_cp_in_6",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 100352,
      .offset_end = 125440,
      .offset_limit = 125504,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 19,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_64_28_28,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_64_28_28,
    },
    {
      .name = "Conv2D_27_off_bias_out_46",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 19,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_64_28_28,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_28_28,
      .per_channel = 0,
      .scale = buff_info_Conv2D_27_off_bias_out_46_quant_scale,
      .offset = buff_info_Conv2D_27_off_bias_out_46_quant_offset,
    },
    {
      .name = "Conv2D_30_off_bias_out_55",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 20,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Conv2D_30_off_bias_out_55_quant_scale,
      .offset = buff_info_Conv2D_30_off_bias_out_55_quant_offset,
    },
    {
      .name = "Dequantize_32_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 21,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "PReLU_33_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 22,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "Quantize_34_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 23,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Quantize_34_out_0_quant_scale,
      .offset = buff_info_Quantize_34_out_0_quant_offset,
    },
    {
      .name = "Conv2D_36_off_bias_out_64",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 24,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Conv2D_36_off_bias_out_64_quant_scale,
      .offset = buff_info_Conv2D_36_off_bias_out_64_quant_offset,
    },
    {
      .name = "Dequantize_38_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 25,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "PReLU_39_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 26,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "Quantize_40_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 27,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Quantize_40_out_0_quant_scale,
      .offset = buff_info_Quantize_40_out_0_quant_offset,
    },
    {
      .name = "Conv2D_42_out_0_cp_in_10_cp_in_11_cp_in_12",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 100352,
      .offset_end = 125440,
      .offset_limit = 125504,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 28,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_64_28_28,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 18,
      .Qn = -3,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_64_28_28,
    },
    {
      .name = "Add_45_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 28,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_64_28_28,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_28_28,
      .per_channel = 0,
      .scale = buff_info_Add_45_out_0_quant_scale,
      .offset = buff_info_Add_45_out_0_quant_offset,
    },
    {
      .name = "Conv2D_48_off_bias_out_82",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 29,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Conv2D_48_off_bias_out_82_quant_scale,
      .offset = buff_info_Conv2D_48_off_bias_out_82_quant_offset,
    },
    {
      .name = "Dequantize_50_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 30,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "PReLU_51_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 31,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "Quantize_52_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 32,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Quantize_52_out_0_quant_scale,
      .offset = buff_info_Quantize_52_out_0_quant_offset,
    },
    {
      .name = "Conv2D_54_off_bias_out_91",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 33,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Conv2D_54_off_bias_out_91_quant_scale,
      .offset = buff_info_Conv2D_54_off_bias_out_91_quant_offset,
    },
    {
      .name = "Dequantize_56_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 34,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "PReLU_57_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 35,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "Quantize_58_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 36,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Quantize_58_out_0_quant_scale,
      .offset = buff_info_Quantize_58_out_0_quant_offset,
    },
    {
      .name = "Conv2D_60_out_0_cp_in_16_cp_in_17_cp_in_18",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 100352,
      .offset_end = 125440,
      .offset_limit = 125504,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 37,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_64_28_28,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_64_28_28,
    },
    {
      .name = "Add_63_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 37,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_64_28_28,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_28_28,
      .per_channel = 0,
      .scale = buff_info_Add_63_out_0_quant_scale,
      .offset = buff_info_Add_63_out_0_quant_offset,
    },
    {
      .name = "Conv2D_66_off_bias_out_109",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 38,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Conv2D_66_off_bias_out_109_quant_scale,
      .offset = buff_info_Conv2D_66_off_bias_out_109_quant_offset,
    },
    {
      .name = "Dequantize_68_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 39,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "PReLU_69_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 40,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "Quantize_70_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 41,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Quantize_70_out_0_quant_scale,
      .offset = buff_info_Quantize_70_out_0_quant_offset,
    },
    {
      .name = "Conv2D_72_off_bias_out_118",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 42,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Conv2D_72_off_bias_out_118_quant_scale,
      .offset = buff_info_Conv2D_72_off_bias_out_118_quant_offset,
    },
    {
      .name = "Dequantize_74_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 43,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "PReLU_75_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 44,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "Quantize_76_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 45,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Quantize_76_out_0_quant_scale,
      .offset = buff_info_Quantize_76_out_0_quant_offset,
    },
    {
      .name = "Conv2D_78_out_0_cp_in_22_cp_in_23_cp_in_24",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 100352,
      .offset_end = 125440,
      .offset_limit = 125504,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 46,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_64_28_28,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 18,
      .Qn = -3,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_64_28_28,
    },
    {
      .name = "Add_81_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 46,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_64_28_28,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_28_28,
      .per_channel = 0,
      .scale = buff_info_Add_81_out_0_quant_scale,
      .offset = buff_info_Add_81_out_0_quant_offset,
    },
    {
      .name = "Conv2D_84_off_bias_out_136",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 47,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Conv2D_84_off_bias_out_136_quant_scale,
      .offset = buff_info_Conv2D_84_off_bias_out_136_quant_offset,
    },
    {
      .name = "Dequantize_86_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 48,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "PReLU_87_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 49,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "Quantize_88_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 50,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Quantize_88_out_0_quant_scale,
      .offset = buff_info_Quantize_88_out_0_quant_offset,
    },
    {
      .name = "Conv2D_90_off_bias_out_145",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 51,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Conv2D_90_off_bias_out_145_quant_scale,
      .offset = buff_info_Conv2D_90_off_bias_out_145_quant_offset,
    },
    {
      .name = "Dequantize_92_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 52,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "PReLU_93_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 53,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
    },
    {
      .name = "Quantize_94_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 54,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_L_1_128_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_28_28,
      .per_channel = 0,
      .scale = buff_info_Quantize_94_out_0_quant_scale,
      .offset = buff_info_Quantize_94_out_0_quant_offset,
    },
    {
      .name = "Conv2D_96_out_0_cp_in_28_cp_in_29_cp_in_30",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 250880,
      .offset_end = 275968,
      .offset_limit = 276032,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 55,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_64_28_28,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_64_28_28,
    },
    {
      .name = "Add_99_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 55,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_64_28_28,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_28_28,
      .per_channel = 0,
      .scale = buff_info_Add_99_out_0_quant_scale,
      .offset = buff_info_Add_99_out_0_quant_offset,
    },
    {
      .name = "Conv2D_102_off_bias_out_163",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 56,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_28_28,
      .per_channel = 0,
      .scale = buff_info_Conv2D_102_off_bias_out_163_quant_scale,
      .offset = buff_info_Conv2D_102_off_bias_out_163_quant_offset,
    },
    {
      .name = "Dequantize_104_out_0",
      .addr_base = {(unsigned char *)(0x34100000UL) /* Equivalent hex address = 0x34100000UL */},
      .offset_start = 0,
      .offset_end = 802816,
      .offset_limit = 802880,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 57,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_28_28,
    },
    {
      .name = "PReLU_105_out_0",
      .addr_base = {(unsigned char *)(0x34100000UL) /* Equivalent hex address = 0x34100000UL */},
      .offset_start = 802816,
      .offset_end = 1605632,
      .offset_limit = 1605696,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 58,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_28_28,
    },
    {
      .name = "Quantize_106_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 59,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_28_28,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_28_28,
      .per_channel = 0,
      .scale = buff_info_Quantize_106_out_0_quant_scale,
      .offset = buff_info_Quantize_106_out_0_quant_offset,
    },
    {
      .name = "Conv2D_108_off_bias_out_172",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 60,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_108_off_bias_out_172_quant_scale,
      .offset = buff_info_Conv2D_108_off_bias_out_172_quant_offset,
    },
    {
      .name = "Dequantize_110_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 61,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "PReLU_111_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 62,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Quantize_112_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 63,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_112_out_0_quant_scale,
      .offset = buff_info_Quantize_112_out_0_quant_offset,
    },
    {
      .name = "Conv2D_114_out_0_cp_in_34_cp_in_35_cp_in_36",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 250880,
      .offset_end = 257152,
      .offset_limit = 257216,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 64,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 18,
      .Qn = -3,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
    },
    {
      .name = "Conv2D_114_off_bias_out_181",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 25088,
      .offset_limit = 25152,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 64,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_114_off_bias_out_181_quant_scale,
      .offset = buff_info_Conv2D_114_off_bias_out_181_quant_offset,
    },
    {
      .name = "Conv2D_117_out_0_cp_in_37_cp_in_38_cp_in_39",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 257152,
      .offset_end = 263424,
      .offset_limit = 263488,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 65,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_256_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Conv2D_117_off_bias_out_190",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 65,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_117_off_bias_out_190_quant_scale,
      .offset = buff_info_Conv2D_117_off_bias_out_190_quant_offset,
    },
    {
      .name = "Dequantize_119_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 66,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "PReLU_120_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 67,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Quantize_121_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 68,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_121_out_0_quant_scale,
      .offset = buff_info_Quantize_121_out_0_quant_offset,
    },
    {
      .name = "Conv2D_123_off_bias_out_199",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 69,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_123_off_bias_out_199_quant_scale,
      .offset = buff_info_Conv2D_123_off_bias_out_199_quant_offset,
    },
    {
      .name = "Dequantize_125_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 70,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "PReLU_126_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 71,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Quantize_127_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 72,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_127_out_0_quant_scale,
      .offset = buff_info_Quantize_127_out_0_quant_offset,
    },
    {
      .name = "Conv2D_129_out_0_cp_in_40_cp_in_41_cp_in_42",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 250880,
      .offset_end = 257152,
      .offset_limit = 257216,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 73,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
    },
    {
      .name = "Add_132_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 25088,
      .offset_end = 50176,
      .offset_limit = 50240,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 73,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
      .per_channel = 0,
      .scale = buff_info_Add_132_out_0_quant_scale,
      .offset = buff_info_Add_132_out_0_quant_offset,
    },
    {
      .name = "Conv2D_135_out_0_cp_in_43_cp_in_44_cp_in_45",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 257152,
      .offset_end = 263424,
      .offset_limit = 263488,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 74,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_256_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Conv2D_135_off_bias_out_217",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 74,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_135_off_bias_out_217_quant_scale,
      .offset = buff_info_Conv2D_135_off_bias_out_217_quant_offset,
    },
    {
      .name = "Dequantize_137_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 75,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "PReLU_138_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 76,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Quantize_139_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 77,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_139_out_0_quant_scale,
      .offset = buff_info_Quantize_139_out_0_quant_offset,
    },
    {
      .name = "Conv2D_141_off_bias_out_226",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 78,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_141_off_bias_out_226_quant_scale,
      .offset = buff_info_Conv2D_141_off_bias_out_226_quant_offset,
    },
    {
      .name = "Dequantize_143_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 79,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "PReLU_144_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 80,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Quantize_145_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 81,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_145_out_0_quant_scale,
      .offset = buff_info_Quantize_145_out_0_quant_offset,
    },
    {
      .name = "Conv2D_147_out_0_cp_in_46_cp_in_47_cp_in_48",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 250880,
      .offset_end = 257152,
      .offset_limit = 257216,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 82,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
    },
    {
      .name = "Add_150_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 25088,
      .offset_limit = 25152,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 82,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
      .per_channel = 0,
      .scale = buff_info_Add_150_out_0_quant_scale,
      .offset = buff_info_Add_150_out_0_quant_offset,
    },
    {
      .name = "Conv2D_153_out_0_cp_in_49_cp_in_50_cp_in_51",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 257152,
      .offset_end = 263424,
      .offset_limit = 263488,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 83,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_256_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Conv2D_153_off_bias_out_244",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 83,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_153_off_bias_out_244_quant_scale,
      .offset = buff_info_Conv2D_153_off_bias_out_244_quant_offset,
    },
    {
      .name = "Dequantize_155_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 84,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "PReLU_156_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 85,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Quantize_157_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 86,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_157_out_0_quant_scale,
      .offset = buff_info_Quantize_157_out_0_quant_offset,
    },
    {
      .name = "Conv2D_159_off_bias_out_253",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 87,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_159_off_bias_out_253_quant_scale,
      .offset = buff_info_Conv2D_159_off_bias_out_253_quant_offset,
    },
    {
      .name = "Dequantize_161_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 88,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "PReLU_162_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 89,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Quantize_163_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 90,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_163_out_0_quant_scale,
      .offset = buff_info_Quantize_163_out_0_quant_offset,
    },
    {
      .name = "Conv2D_165_out_0_cp_in_52_cp_in_53_cp_in_54",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 250880,
      .offset_end = 257152,
      .offset_limit = 257216,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 91,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
    },
    {
      .name = "Add_168_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 25088,
      .offset_end = 50176,
      .offset_limit = 50240,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 91,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
      .per_channel = 0,
      .scale = buff_info_Add_168_out_0_quant_scale,
      .offset = buff_info_Add_168_out_0_quant_offset,
    },
    {
      .name = "Conv2D_171_out_0_cp_in_55_cp_in_56_cp_in_57",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 257152,
      .offset_end = 263424,
      .offset_limit = 263488,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 92,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_256_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Conv2D_171_off_bias_out_271",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 92,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_171_off_bias_out_271_quant_scale,
      .offset = buff_info_Conv2D_171_off_bias_out_271_quant_offset,
    },
    {
      .name = "Dequantize_173_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 93,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "PReLU_174_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 94,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Quantize_175_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 95,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_175_out_0_quant_scale,
      .offset = buff_info_Quantize_175_out_0_quant_offset,
    },
    {
      .name = "Conv2D_177_off_bias_out_280",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 96,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_177_off_bias_out_280_quant_scale,
      .offset = buff_info_Conv2D_177_off_bias_out_280_quant_offset,
    },
    {
      .name = "Dequantize_179_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 97,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "PReLU_180_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 98,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Quantize_181_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 99,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_181_out_0_quant_scale,
      .offset = buff_info_Quantize_181_out_0_quant_offset,
    },
    {
      .name = "Conv2D_183_out_0_cp_in_58_cp_in_59_cp_in_60",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 250880,
      .offset_end = 257152,
      .offset_limit = 257216,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 100,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
    },
    {
      .name = "Add_186_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 25088,
      .offset_limit = 25152,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 100,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
      .per_channel = 0,
      .scale = buff_info_Add_186_out_0_quant_scale,
      .offset = buff_info_Add_186_out_0_quant_offset,
    },
    {
      .name = "Conv2D_189_out_0_cp_in_61_cp_in_62_cp_in_63",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 257152,
      .offset_end = 263424,
      .offset_limit = 263488,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 101,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_256_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Conv2D_189_off_bias_out_298",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 101,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_189_off_bias_out_298_quant_scale,
      .offset = buff_info_Conv2D_189_off_bias_out_298_quant_offset,
    },
    {
      .name = "Dequantize_191_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 102,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "PReLU_192_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 103,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Quantize_193_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 104,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_193_out_0_quant_scale,
      .offset = buff_info_Quantize_193_out_0_quant_offset,
    },
    {
      .name = "Conv2D_195_off_bias_out_307",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 105,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_195_off_bias_out_307_quant_scale,
      .offset = buff_info_Conv2D_195_off_bias_out_307_quant_offset,
    },
    {
      .name = "Dequantize_197_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 106,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "PReLU_198_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 107,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Quantize_199_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 108,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_199_out_0_quant_scale,
      .offset = buff_info_Quantize_199_out_0_quant_offset,
    },
    {
      .name = "Conv2D_201_out_0_cp_in_64_cp_in_65_cp_in_66",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 250880,
      .offset_end = 257152,
      .offset_limit = 257216,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 109,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
    },
    {
      .name = "Add_204_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 25088,
      .offset_end = 50176,
      .offset_limit = 50240,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 109,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
      .per_channel = 0,
      .scale = buff_info_Add_204_out_0_quant_scale,
      .offset = buff_info_Add_204_out_0_quant_offset,
    },
    {
      .name = "Conv2D_207_out_0_cp_in_67_cp_in_68_cp_in_69",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 257152,
      .offset_end = 263424,
      .offset_limit = 263488,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 110,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_256_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Conv2D_207_off_bias_out_325",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 110,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_207_off_bias_out_325_quant_scale,
      .offset = buff_info_Conv2D_207_off_bias_out_325_quant_offset,
    },
    {
      .name = "Dequantize_209_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 111,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "PReLU_210_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 112,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Quantize_211_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 113,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_211_out_0_quant_scale,
      .offset = buff_info_Quantize_211_out_0_quant_offset,
    },
    {
      .name = "Conv2D_213_off_bias_out_334",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 250880,
      .offset_limit = 250944,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 114,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_213_off_bias_out_334_quant_scale,
      .offset = buff_info_Conv2D_213_off_bias_out_334_quant_offset,
    },
    {
      .name = "Dequantize_215_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 115,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "PReLU_216_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 200704,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 116,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
    },
    {
      .name = "Quantize_217_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 451584,
      .offset_limit = 451648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 117,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_217_out_0_quant_scale,
      .offset = buff_info_Quantize_217_out_0_quant_offset,
    },
    {
      .name = "Conv2D_219_out_0_cp_in_70_cp_in_71_cp_in_72",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 25088,
      .offset_end = 31360,
      .offset_limit = 31424,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 118,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
    },
    {
      .name = "Add_222_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 25088,
      .offset_limit = 25152,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 118,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_14_14,
      .per_channel = 0,
      .scale = buff_info_Add_222_out_0_quant_scale,
      .offset = buff_info_Add_222_out_0_quant_offset,
    },
    {
      .name = "Conv2D_225_out_0_cp_in_73_cp_in_74_cp_in_75",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 401408,
      .offset_end = 407680,
      .offset_limit = 407744,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 119,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_512_14_14,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_512_14_14,
    },
    {
      .name = "Conv2D_225_off_bias_out_352",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 119,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_512_14_14,
      .per_channel = 0,
      .scale = buff_info_Conv2D_225_off_bias_out_352_quant_scale,
      .offset = buff_info_Conv2D_225_off_bias_out_352_quant_offset,
    },
    {
      .name = "Dequantize_227_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 120,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_512_14_14,
    },
    {
      .name = "PReLU_228_out_0",
      .addr_base = {(unsigned char *)(0x34270000UL) /* Equivalent hex address = 0x34270000UL */},
      .offset_start = 0,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 121,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_512_14_14,
    },
    {
      .name = "Quantize_229_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 122,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_14_14,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_512_14_14,
      .per_channel = 0,
      .scale = buff_info_Quantize_229_out_0_quant_scale,
      .offset = buff_info_Quantize_229_out_0_quant_offset,
    },
    {
      .name = "Conv2D_231_off_bias_out_361",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 100352,
      .offset_end = 125440,
      .offset_limit = 125504,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 123,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_512_7_7,
      .per_channel = 0,
      .scale = buff_info_Conv2D_231_off_bias_out_361_quant_scale,
      .offset = buff_info_Conv2D_231_off_bias_out_361_quant_offset,
    },
    {
      .name = "Dequantize_233_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 124,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_512_7_7,
    },
    {
      .name = "PReLU_234_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 100352,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 125,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_512_7_7,
    },
    {
      .name = "Quantize_235_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 25088,
      .offset_limit = 25152,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 126,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_512_7_7,
      .per_channel = 0,
      .scale = buff_info_Quantize_235_out_0_quant_scale,
      .offset = buff_info_Quantize_235_out_0_quant_offset,
    },
    {
      .name = "Conv2D_237_out_0_cp_in_76_cp_in_77_cp_in_78",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 25088,
      .offset_end = 26656,
      .offset_limit = 26720,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 127,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_7_7,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 18,
      .Qn = -3,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_128_7_7,
    },
    {
      .name = "Conv2D_237_off_bias_out_370",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 100352,
      .offset_end = 106624,
      .offset_limit = 106688,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 127,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_7_7,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_7_7,
      .per_channel = 0,
      .scale = buff_info_Conv2D_237_off_bias_out_370_quant_scale,
      .offset = buff_info_Conv2D_237_off_bias_out_370_quant_offset,
    },
    {
      .name = "Conv2D_240_out_0_cp_in_79_cp_in_80_cp_in_81",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 62720,
      .offset_end = 64288,
      .offset_limit = 64352,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 128,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_256_7_7,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
    },
    {
      .name = "Conv2D_240_off_bias_out_379",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 50176,
      .offset_end = 62720,
      .offset_limit = 62784,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 128,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
      .per_channel = 0,
      .scale = buff_info_Conv2D_240_off_bias_out_379_quant_scale,
      .offset = buff_info_Conv2D_240_off_bias_out_379_quant_offset,
    },
    {
      .name = "Dequantize_242_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 50176,
      .offset_limit = 50240,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 129,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
    },
    {
      .name = "PReLU_243_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 50176,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 130,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
    },
    {
      .name = "Quantize_244_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 12544,
      .offset_limit = 12608,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 131,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
      .per_channel = 0,
      .scale = buff_info_Quantize_244_out_0_quant_scale,
      .offset = buff_info_Quantize_244_out_0_quant_offset,
    },
    {
      .name = "Conv2D_246_off_bias_out_388",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 50176,
      .offset_end = 62720,
      .offset_limit = 62784,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 132,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
      .per_channel = 0,
      .scale = buff_info_Conv2D_246_off_bias_out_388_quant_scale,
      .offset = buff_info_Conv2D_246_off_bias_out_388_quant_offset,
    },
    {
      .name = "Dequantize_248_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 50176,
      .offset_limit = 50240,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 133,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
    },
    {
      .name = "PReLU_249_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 50176,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 134,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
    },
    {
      .name = "Quantize_250_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 12544,
      .offset_limit = 12608,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 135,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
      .per_channel = 0,
      .scale = buff_info_Quantize_250_out_0_quant_scale,
      .offset = buff_info_Quantize_250_out_0_quant_offset,
    },
    {
      .name = "Conv2D_252_out_0_cp_in_82_cp_in_83_cp_in_84",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 12544,
      .offset_end = 14112,
      .offset_limit = 14176,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 136,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_7_7,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_128_7_7,
    },
    {
      .name = "Add_255_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 106624,
      .offset_end = 112896,
      .offset_limit = 112960,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 136,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_7_7,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_7_7,
      .per_channel = 0,
      .scale = buff_info_Add_255_out_0_quant_scale,
      .offset = buff_info_Add_255_out_0_quant_offset,
    },
    {
      .name = "Conv2D_258_out_0_cp_in_85_cp_in_86_cp_in_87",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 62720,
      .offset_end = 64288,
      .offset_limit = 64352,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 137,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_256_7_7,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
    },
    {
      .name = "Conv2D_258_off_bias_out_406",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 50176,
      .offset_end = 62720,
      .offset_limit = 62784,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 137,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
      .per_channel = 0,
      .scale = buff_info_Conv2D_258_off_bias_out_406_quant_scale,
      .offset = buff_info_Conv2D_258_off_bias_out_406_quant_offset,
    },
    {
      .name = "Dequantize_260_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 50176,
      .offset_limit = 50240,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 138,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
    },
    {
      .name = "PReLU_261_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 50176,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 139,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
    },
    {
      .name = "Quantize_262_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 12544,
      .offset_limit = 12608,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 140,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
      .per_channel = 0,
      .scale = buff_info_Quantize_262_out_0_quant_scale,
      .offset = buff_info_Quantize_262_out_0_quant_offset,
    },
    {
      .name = "Conv2D_264_off_bias_out_415",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 50176,
      .offset_end = 62720,
      .offset_limit = 62784,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 141,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
      .per_channel = 0,
      .scale = buff_info_Conv2D_264_off_bias_out_415_quant_scale,
      .offset = buff_info_Conv2D_264_off_bias_out_415_quant_offset,
    },
    {
      .name = "Dequantize_266_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 50176,
      .offset_limit = 50240,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 142,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
    },
    {
      .name = "PReLU_267_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 50176,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 143,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
    },
    {
      .name = "Quantize_268_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 12544,
      .offset_limit = 12608,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 144,
      .batch = 256,
      .mem_shape = buff_info__mem_shape_L_1_256_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_256_7_7,
      .per_channel = 0,
      .scale = buff_info_Quantize_268_out_0_quant_scale,
      .offset = buff_info_Quantize_268_out_0_quant_offset,
    },
    {
      .name = "Conv2D_270_out_0_cp_in_88_cp_in_89_cp_in_90",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 18816,
      .offset_end = 20384,
      .offset_limit = 20448,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 145,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_7_7,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_128_7_7,
    },
    {
      .name = "Add_273_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 12544,
      .offset_end = 18816,
      .offset_limit = 18880,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 145,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_128_7_7,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_7_7,
      .per_channel = 0,
      .scale = buff_info_Add_273_out_0_quant_scale,
      .offset = buff_info_Add_273_out_0_quant_offset,
    },
    {
      .name = "Conv2D_276_out_0_cp_in_91_cp_in_92_cp_in_93",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 125440,
      .offset_end = 127008,
      .offset_limit = 127072,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 146,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_512_7_7,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_512_7_7,
    },
    {
      .name = "Conv2D_276_off_bias_out_433",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 100352,
      .offset_end = 125440,
      .offset_limit = 125504,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 146,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_512_7_7,
      .per_channel = 0,
      .scale = buff_info_Conv2D_276_off_bias_out_433_quant_scale,
      .offset = buff_info_Conv2D_276_off_bias_out_433_quant_offset,
    },
    {
      .name = "Dequantize_278_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 147,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_512_7_7,
    },
    {
      .name = "PReLU_279_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 100352,
      .offset_end = 200704,
      .offset_limit = 200768,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 148,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_512_7_7,
    },
    {
      .name = "Quantize_280_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 25088,
      .offset_limit = 25152,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 149,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_512_7_7,
      .per_channel = 0,
      .scale = buff_info_Quantize_280_out_0_quant_scale,
      .offset = buff_info_Quantize_280_out_0_quant_offset,
    },
    {
      .name = "____1174",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 154624,
      .offset_end = 155648,
      .offset_limit = 155712,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 150,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_512_1_1,
    },
    {
      .name = "____1168",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 158720,
      .offset_end = 159744,
      .offset_limit = 159808,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 150,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_512_1_1,
    },
    {
      .name = "Conv2D_282_zero_off_out_436",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 100352,
      .offset_end = 150528,
      .offset_limit = 150592,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 150,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 15,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT16,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_512_7_7,
      .per_channel = 0,
      .scale = buff_info_Conv2D_282_zero_off_out_436_quant_scale,
      .offset = buff_info_Conv2D_282_zero_off_out_436_quant_offset,
    },
    {
      .name = "Conv2D_282_zero_off_out_436_inserted_out1187",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 151,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_512_7_7,
    },
    {
      .name = "____1171",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 156672,
      .offset_end = 158720,
      .offset_limit = 158784,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 152,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_512_1_1,
    },
    {
      .name = "____1171_inserted_out1192",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 156672,
      .offset_end = 157696,
      .offset_limit = 157760,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 153,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_512_1_1,
    },
    {
      .name = "Conv2D_282_zero_off_out_436_inserted_out1188",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 154,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_512_7_7,
    },
    {
      .name = "____1165",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 152576,
      .offset_end = 154624,
      .offset_limit = 154688,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 155,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_512_1_1,
    },
    {
      .name = "____1165_inserted_out1191",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 152576,
      .offset_end = 153600,
      .offset_limit = 153664,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 156,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_512_1_1,
    },
    {
      .name = "Conv2D_282_zero_off_out_436_inserted_out1189",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 100352,
      .offset_limit = 100416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 157,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_7_7,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_512_7_7,
    },
    {
      .name = "____1162",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 150528,
      .offset_end = 152576,
      .offset_limit = 152640,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 158,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_512_1_1,
    },
    {
      .name = "____1162_inserted_out1190",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 150528,
      .offset_end = 151552,
      .offset_limit = 151616,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 159,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_512_1_1,
    },
    {
      .name = "____1176",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 1024,
      .offset_limit = 1088,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 160,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_512_1_1,
    },
    {
      .name = "____1175",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 155648,
      .offset_end = 156672,
      .offset_limit = 156736,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 160,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 16,
      .Qn = -1,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_512_1_1,
    },
    {
      .name = "Conv2D_282_off_bias_out_442",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 1024,
      .offset_end = 1536,
      .offset_limit = 1600,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 161,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_F_1_512_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_512_1_1,
      .per_channel = 0,
      .scale = buff_info_Conv2D_282_off_bias_out_442_quant_scale,
      .offset = buff_info_Conv2D_282_off_bias_out_442_quant_offset,
    },
    {
      .name = "Gemm_286_conv_4_off_bias_out_451",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 128,
      .offset_limit = 192,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 162,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_F_1_128_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_1_1,
      .per_channel = 0,
      .scale = buff_info_Gemm_286_conv_4_off_bias_out_451_quant_scale,
      .offset = buff_info_Gemm_286_conv_4_off_bias_out_451_quant_offset,
    },
    {
      .name = "Gemm_286_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 128,
      .offset_limit = 192,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 162,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1_128,
      .mem_ndims = 2,
      .chpos = CHPos_UNDEFINED,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128,
      .per_channel = 0,
      .scale = buff_info_Gemm_286_out_0_quant_scale,
      .offset = buff_info_Gemm_286_out_0_quant_offset,
    },
    {
      .name = "Dequantize_288_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 512,
      .offset_end = 1024,
      .offset_limit = 1088,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 163,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1_128,
      .mem_ndims = 2,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128,
    },
    {
      .name = NULL,
    }
  };

  return buff_info;
}

